{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Horse Racing\n",
    "\n",
    "----\n",
    "\n",
    "Charles Spencer GA DSI8 Singapore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Me: https://docs.google.com/document/d/15_TQGryrslBMF6tk0QzfTw_YMzcEhzGqaSD0I440_CI/edit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, PowerTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import all data: \n",
    "\n",
    "df = pd.read_csv('./datasets/stc_data.csv', parse_dates=['date'], dayfirst=True)\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "#df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.loc[df['horse_name'] == 'STORMY VIEW']\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df['date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Indexing:\n",
    "df['indexing'] = np.arange(len(df)) #new indexing column for re-ranking in original order (date & race)\n",
    "df['surf_numb'] = df.apply(lambda x: 1 if x['surface'] == 'T' else .1, axis=1) #conv 'surface' P to 0.1 & T to 1\n",
    "df['indexing_surf_dist'] = df.surf_numb * df.distance # new column for surface & distance\n",
    "df['indexing_surf_dist_bar'] = df.indexing_surf_dist * df.bar # new column for suf; dist & bar\n",
    "df['indexing_date_race'] = df[\"date\"].map(str) + df[\"race\"].map(str) # new categorical column for date & race\n",
    "df['indexing_date_horse'] = df[\"date\"].map(str) + df[\"horse_name\"].map(str) # new cat. column for date & horse\n",
    "\n",
    "df['indexing_surf_dist_10'] = df['indexing_surf_dist'].astype(str)\n",
    "df['indexing_surf_dist_horse'] = df[\"indexing_surf_dist_10\"].map(str) + df[\"horse_name\"].map(str) # new column\n",
    "#df['indexing_surf_dist_class'] = df[\"indexing_surf_dist_10\"].map(str) + df[\"class\"].map(str)\n",
    "\n",
    "# Cleaning:\n",
    "df['win_div_3'] = df['win_div_3'].str.replace('$', '') # 'Win_Div_3': Remove '$' and convert to 'int'\n",
    "df['win_div_3'] = df['win_div_3'].astype(int)\n",
    "df = df.assign(lbw = 0 - df['lbw']) # convert LBW to negative numbers.\n",
    "\n",
    "# Additional Calculations for our Engineered Features & Analysis: \n",
    "# Favorite/Longshot Bias Bins:\n",
    "#bin_ranges = [0, 20.5, 5000.5]\n",
    "#bin_names = ['$6-20; Prob. >=25%', '$21+; Prob. <25%']\n",
    "# implied prob   >25%;      25-0%   \n",
    "\n",
    "#df['binned_win_div_3'] = pd.cut((df['win_div_3']), bins=bin_ranges,labels=bin_names)\n",
    "#df = df.assign(public_prob = 5 / df['win_div_3'] * 100)\n",
    "df['total_count'] = df.apply(lambda x: 1 if x['lbw'] == 0 else 1, axis=1)\n",
    "df['win_count'] = df.apply(lambda x: 1 if x['lbw'] == 0 else 0, axis=1)\n",
    "#df['total_wager'] = df.apply(lambda x: 5 if x['lbw'] == 0 else 5, axis=1)\n",
    "#df = df.assign(return_wager = df['win_div_3'] * df['win_count'])\n",
    "#df['loss_rebate'] = df.apply(lambda x: .5 if x['win_count'] == 0 else 0, axis=1)\n",
    "#df = df.assign(profit_loss = df['return_wager'] - df['total_wager'] + df['loss_rebate'])\n",
    "\n",
    "#drop unused columns:\n",
    "df = df.drop(['Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', \n",
    "               'Unnamed: 28', 'time_2', 'margin_2', 'finish_3', 'no_3', 'horse_name_3', 'rating_3',\n",
    "               'c_weight_3', 'jockey_3', 'trainer_3', 'draw_3', 'running_pos_3', 'finish_time_3',\n",
    "             'lbw_3', 'h_weight_3'], axis=1)\n",
    "\n",
    "#drop other currently unused columns:\n",
    "df = df.drop(['horse_number', 'gear', 'running_position', 'pl', 'time', 'off_rail_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return df to original order:\n",
    "df = df.sort_values(by=['indexing'], ascending =True)\n",
    "df = df.reset_index()\n",
    "df = df.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#race_dates = test_1    '13/01/2019','11/01/2019','06/01/2019','01/01/2019'\n",
    "train_1 = df[(df['date'] > '31/Dec/2017') & (df['date'] < '01/Jan/2019')]\n",
    "test_1 = df[(df['date'] >= '01/Jan/2019') & (df['date'] <= '13/Jan/2019')]\n",
    "\n",
    "#race_dates = test_2    '25/01/2019','20/01/2019','18/01/2019',\n",
    "train_2 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '13/Jan/2019')]\n",
    "test_2 = df[(df['date'] >= '18/Jan/2019') & (df['date'] <= '25/Jan/2019')]\n",
    "\n",
    "#race_dates = test_3    '08/02/2019','06/02/2019','03/02/2019','01/02/2019',\n",
    "train_3 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '25/Jan/2019')]\n",
    "test_3 = df[(df['date'] >= '01/Feb/2019') & (df['date'] <= '08/Feb/2019')]\n",
    "\n",
    "#race_dates = test_4    '22/02/2019','17/02/2019','15/02/2019',\n",
    "train_4 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '08/Feb/2019')]\n",
    "test_4 = df[(df['date'] >= '15/Feb/2019') & (df['date'] <= '22/Feb/2019')]\n",
    "\n",
    "#race_dates = test_5    '10/03/2019','08/03/2019','03/03/2019','01/03/2019',\n",
    "train_5 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '22/Feb/2019')]\n",
    "test_5 = df[(df['date'] >= '01/Mar/2019') & (df['date'] <= '10/Mar/2019')]\n",
    "\n",
    "#race_dates = test_6    '29/03/2019','24/03/2019','22/03/2019','17/03/2019','15/03/2019',\n",
    "train_6 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '10/Mar/2019')]\n",
    "test_6 = df[(df['date'] >= '15/Mar/2019') & (df['date'] <= '29/Mar/2019')]\n",
    "\n",
    "#race_dates = test_7    '14/04/2019','12/04/2019','07/04/2019','05/04/2019',\n",
    "train_7 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '29/Mar/2019')]\n",
    "test_7 = df[(df['date'] >= '05/Apr/2019') & (df['date'] <= '14/Apr/2019')]\n",
    "\n",
    "#race_dates = test_8    '26/04/2019','21/04/2019','19/04/2019',\n",
    "train_8 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '14/Apr/2019')]\n",
    "test_8 = df[(df['date'] >= '19/Apr/2019') & (df['date'] <= '26/Apr/2019')]\n",
    "\n",
    "#race_dates = test_9    '12/05/2019','10/05/2019','05/05/2019','03/05/2019',\n",
    "train_9 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '26/Apr/2019')]\n",
    "test_9 = df[(df['date'] >= '03/May/2019') & (df['date'] <= '12/May/2019')]\n",
    "\n",
    "#race_dates = test_10    '01/06/2019','31/05/2019','25/05/2019','19/05/2019','17/05/2019',\n",
    "train_10 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '12/May/2019')]\n",
    "test_10 = df[(df['date'] >= '17/May/2019') & (df['date'] <= '01/Jun/2019')]\n",
    "\n",
    "#race_dates = test_11    '15/06/2019','14/06/2019','09/06/2019','07/06/2019',\n",
    "train_11 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '01/Jun/2019')]\n",
    "test_11 = df[(df['date'] >= '07/Jun/2019') & (df['date'] <= '15/Jun/2019')]\n",
    "\n",
    "#race_dates = test_12    '30/06/2019','28/06/2019','21/06/2019',\n",
    "train_12 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '15/Jun/2019')]\n",
    "test_12 = df[(df['date'] >= '21/Jun/2019') & (df['date'] <= '30/Jun/2019')]\n",
    "\n",
    "#race_dates = test_13    '21/07/2019', '19/07/2019', '12/07/2019', '07/07/2019', '05/07/2019', \n",
    "train_13 = df[(df['date'] > '31/Dec/2017') & (df['date'] <= '30/Jun/2019')]\n",
    "test_13 = df[(df['date'] >= '05/Jul/2019') & (df['date'] <= '21/Jul/2019')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Score Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_13 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_13.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_surf_dist')\n",
    "train_13.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_13 = train_13.assign(lengths_vs_standard_1 = \n",
    "                           ((train_13['avg_km_hr_2'] - train_13['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_13['lengths_vs_standard_1'].groupby(train_13['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_13 = pd.merge(train_13, temp, on='horse_name')\n",
    "train_13.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_13.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_13.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_13.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_13.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_13.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_13.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_13.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_1 = ((train_13['horse_median_vs_standard'] - train_13['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_1a = ((train_13['horse_mean_vs_standard'] - train_13['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_1b = ((train_13['horse_top_qtr_vs_standard'] - train_13['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_1c = ((train_13['horse_max_vs_standard'] - train_13['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_13 = train_13.assign(feature_1d = ((train_13['horse_min_vs_standard'] - train_13['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_13 = train_13.assign(feature_1e = ((train_13['horse_bot_qtr_vs_standard'] - train_13['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_13.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_13.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_surf_dist')\n",
    "train_13.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_13 = train_13.assign(lengths_vs_standard_3 = (((((train_13['l100m_km_hr_2'])+(train_13['avg_km_hr_2']))/2) \n",
    "                                         - train_13['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_13['lengths_vs_standard_3'].groupby(train_13['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_13 = pd.merge(train_13, temp, on='horse_name')\n",
    "train_13.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_13.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_13.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_13.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_13.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_13.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_13.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_13.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_3 = ((train_13['horse_median_vs_standard_3'] - train_13['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_3a = ((train_13['horse_mean_vs_standard_3'] - train_13['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_3b = ((train_13['horse_top_qtr_vs_standard_3'] - train_13['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_13 = train_13.assign(feature_3c = ((train_13['horse_max_vs_standard_3'] - train_13['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_13 = train_13.assign(feature_3d = ((train_13['horse_min_vs_standard_3'] - train_13['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_13.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, temp, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_13 = train_13.assign(feature_3e = ((train_13['horse_bot_qtr_vs_standard_3'] - train_13['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "train_13 = train_13.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_13[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_13 = pd.merge(train_13, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_13.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, jockey_pct_race, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_13 = train_13.assign(jock_pct_race_f5 = \n",
    "               ((train_13['jock_pct'] - train_13['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_13[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_13 = pd.merge(train_13, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_13.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, trainer_pct_race, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_13 = train_13.assign(trainer_pct_race_f6 = \n",
    "               ((train_13['trainer_pct'] - train_13['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_13 = train_13.assign(jock_trainer_combo = (train_13['trainer'] + train_13['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_13[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_13 = pd.merge(train_13, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_13.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_13 = train_13.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_13['jock_trainer_win_pct'] - train_13['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_13.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_13 = pd.merge(train_13, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_13.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_13 = pd.merge(train_13, bar_win_max_race, on='indexing_date_race')\n",
    "train_13.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_13 = train_13.assign(bar_win_race_f8 = ((train_13['bar_win_mean'] - train_13['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_13 = train_13.sort_values(by=['indexing'], ascending =True)\n",
    "train_13 = train_13.reset_index()\n",
    "train_13 = train_13.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_13:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_13.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_13.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_13 = test_13.assign(feature_1 = ((test_13['horse_median_vs_standard'] - \n",
    "                                             test_13['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_13.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_13.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1a, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_1a = ((test_13['horse_mean_vs_standard'] - \n",
    "                                             test_13['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_13.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_13.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1b, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_1b = ((test_13['horse_top_qtr_vs_standard'] - \n",
    "                                             test_13['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_13.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_13.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1c, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_1c = ((test_13['horse_max_vs_standard'] - \n",
    "                                             test_13['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_13.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_13.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1d, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_1d = ((test_13['horse_min_vs_standard'] - \n",
    "                                             test_13['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_13.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_13.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_1e, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_1e = ((test_13['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_13['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_13.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_13.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_13 = test_13.assign(feature_3 = ((test_13['horse_median_vs_standard_3'] - \n",
    "                                             test_13['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_13.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_13.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3a, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_3a = ((test_13['horse_mean_vs_standard_3'] - \n",
    "                                             test_13['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_13.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_13.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3b, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_3b = ((test_13['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_13['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_13.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_13.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3c, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_3c = ((test_13['horse_max_vs_standard_3'] - \n",
    "                                             test_13['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_13.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_13.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3d, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_3d = ((test_13['horse_min_vs_standard_3'] - \n",
    "                                             test_13['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_13.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_13.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_13.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_3e, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_13 = test_13.assign(feature_3e = ((test_13['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_13['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_13.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_13 = pd.merge(test_13, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_13.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_13.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, temp_5, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_13 = test_13.assign(jock_pct_race_f5 = \n",
    "               ((test_13['jock_pct'] - test_13['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_13.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_13 = pd.merge(test_13, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_13.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_13.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_13 = pd.merge(test_13, temp_6, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_13 = test_13.assign(trainer_pct_race_f6 = \n",
    "               ((test_13['trainer_pct'] - test_13['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_13 = test_13.assign(jock_trainer_combo = (test_13['trainer'] + test_13['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_13.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_13 = pd.merge(test_13, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_13.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_13.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_13 = pd.merge(test_13, temp_7, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_13 = test_13.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_13['jock_trainer_win_pct'] - test_13['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_13.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_13 = pd.merge(test_13, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_13.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_13.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_13 = pd.merge(test_13, temp_8, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_13 = test_13.assign(bar_win_race_f8 = \n",
    "               ((test_13['bar_win_mean'] - test_13['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_13 = test_13.sort_values(by=['indexing'], ascending =True)\n",
    "test_13 = test_13.reset_index()\n",
    "test_13 = test_13.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_13[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_13[['STORMY VIEW']].head()\n",
    "\n",
    "#test_13.loc[(test_13['date'] == '2019-07-07') & (test_13['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_13[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_13['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_13[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_13 = test_13.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_13.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, race_lbw_max, on='indexing_date_race')\n",
    "test_13.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_13 = test_13.sort_values(by=['indexing'], ascending =True)\n",
    "test_13 = test_13.reset_index()\n",
    "test_13 = test_13.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_13 = test_13.assign(race_lbw_pred = ((test_13['lbw_pred'] - test_13['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_13.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_13['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_13['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_13.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_13 = pd.merge(test_13, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_13.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_13 = test_13.assign(race_prob_pred = ((test_13['prob_pred'] / test_13['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_13 = test_13.assign(race_win_div_pred = ((5 / ((test_13['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_13.loc[(test_13['date'] == '2019-07-07') & (test_13['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_13[test_13.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True)  \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_13 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>3</td>\n",
       "      <td>VULCAN</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4</td>\n",
       "      <td>PACIFIC MYSTICAL</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>7.375000</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>5</td>\n",
       "      <td>EASY DOES IT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.562500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>7</td>\n",
       "      <td>REVOLUTION</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>18.187500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>8</td>\n",
       "      <td>SURPASS NATURAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>9</td>\n",
       "      <td>TURF PRINCESS</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>20.062500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>2</td>\n",
       "      <td>STORMY VIEW</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>4</td>\n",
       "      <td>ROCKET STAR</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>4</td>\n",
       "      <td>ADMIRAL WINSTON</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>13.545455</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>6</td>\n",
       "      <td>CHOCANTE</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>9</td>\n",
       "      <td>LORD O'REILLY</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>2</td>\n",
       "      <td>AMAZING CHOICE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>3</td>\n",
       "      <td>MR BACHARACH</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>4</td>\n",
       "      <td>RIVER RADIANCE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>7</td>\n",
       "      <td>-5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>5</td>\n",
       "      <td>BIG HEARTED</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>10</td>\n",
       "      <td>IRVING LIPSCHITZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.812500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race        horse_name   lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "25  2019-07-05     3            VULCAN  -5.5          13.500000         18     -5     0.5          0\n",
       "40  2019-07-05     4  PACIFIC MYSTICAL  -5.6           7.375000         13     -5     0.5          0\n",
       "46  2019-07-05     5      EASY DOES IT   0.0          13.562500         22     -5    22.0          1\n",
       "71  2019-07-05     7        REVOLUTION  -0.7          18.187500         20     -5     0.5          0\n",
       "81  2019-07-05     8   SURPASS NATURAL   0.0           5.812500         12     -5    12.0          1\n",
       "96  2019-07-05     9     TURF PRINCESS  -0.5          20.062500         24     -5     0.5          0\n",
       "124 2019-07-07     2       STORMY VIEW  -7.8           6.125000          8     -5     0.5          0\n",
       "137 2019-07-07     4       ROCKET STAR  -2.0           9.312500         10     -5     0.5          0\n",
       "141 2019-07-07     4   ADMIRAL WINSTON  -5.2          13.545455         20     -5     0.5          0\n",
       "161 2019-07-07     6          CHOCANTE  -2.3          12.687500         16     -5     0.5          0\n",
       "207 2019-07-07     9     LORD O'REILLY -10.9          13.500000         27     -5     0.5          0\n",
       "233 2019-07-12     2    AMAZING CHOICE   0.0           8.250000         10     -5    10.0          1\n",
       "358 2019-07-19     3      MR BACHARACH  -3.6          11.562500         20     -5     0.5          0\n",
       "368 2019-07-19     4    RIVER RADIANCE   0.0           5.625000          7     -5     7.0          1\n",
       "383 2019-07-19     5       BIG HEARTED  -2.6           9.125000         16     -5     0.5          0\n",
       "554 2019-07-21    10  IRVING LIPSCHITZ   0.0          15.812500         24     -5    24.0          1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_12 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_12.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_surf_dist')\n",
    "train_12.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_12 = train_12.assign(lengths_vs_standard_1 = \n",
    "                           ((train_12['avg_km_hr_2'] - train_12['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_12['lengths_vs_standard_1'].groupby(train_12['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_12 = pd.merge(train_12, temp, on='horse_name')\n",
    "train_12.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_12.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_12.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_12.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_12.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_12.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_12.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_12.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_1 = ((train_12['horse_median_vs_standard'] - train_12['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_1a = ((train_12['horse_mean_vs_standard'] - train_12['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_1b = ((train_12['horse_top_qtr_vs_standard'] - train_12['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_1c = ((train_12['horse_max_vs_standard'] - train_12['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_12 = train_12.assign(feature_1d = ((train_12['horse_min_vs_standard'] - train_12['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_12 = train_12.assign(feature_1e = ((train_12['horse_bot_qtr_vs_standard'] - train_12['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_12.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_12.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_surf_dist')\n",
    "train_12.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_12 = train_12.assign(lengths_vs_standard_3 = (((((train_12['l100m_km_hr_2'])+(train_12['avg_km_hr_2']))/2) \n",
    "                                         - train_12['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_12['lengths_vs_standard_3'].groupby(train_12['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_12 = pd.merge(train_12, temp, on='horse_name')\n",
    "train_12.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_12.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_12.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_12.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_12.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_12.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_12.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_12.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_3 = ((train_12['horse_median_vs_standard_3'] - train_12['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_3a = ((train_12['horse_mean_vs_standard_3'] - train_12['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_3b = ((train_12['horse_top_qtr_vs_standard_3'] - train_12['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_12 = train_12.assign(feature_3c = ((train_12['horse_max_vs_standard_3'] - train_12['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_12 = train_12.assign(feature_3d = ((train_12['horse_min_vs_standard_3'] - train_12['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_12.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, temp, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_12 = train_12.assign(feature_3e = ((train_12['horse_bot_qtr_vs_standard_3'] - train_12['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "train_12 = train_12.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_12[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_12 = pd.merge(train_12, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_12.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, jockey_pct_race, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_12 = train_12.assign(jock_pct_race_f5 = \n",
    "               ((train_12['jock_pct'] - train_12['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_12[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_12 = pd.merge(train_12, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_12.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, trainer_pct_race, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_12 = train_12.assign(trainer_pct_race_f6 = \n",
    "               ((train_12['trainer_pct'] - train_12['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_12 = train_12.assign(jock_trainer_combo = (train_12['trainer'] + train_12['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_12[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_12 = pd.merge(train_12, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_12.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_12 = train_12.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_12['jock_trainer_win_pct'] - train_12['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_12.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_12 = pd.merge(train_12, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_12.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_12 = pd.merge(train_12, bar_win_max_race, on='indexing_date_race')\n",
    "train_12.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_12 = train_12.assign(bar_win_race_f8 = ((train_12['bar_win_mean'] - train_12['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_12 = train_12.sort_values(by=['indexing'], ascending =True)\n",
    "train_12 = train_12.reset_index()\n",
    "train_12 = train_12.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_12.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_12.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_12 = test_12.assign(feature_1 = ((test_12['horse_median_vs_standard'] - \n",
    "                                             test_12['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_12.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_12.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1a, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_1a = ((test_12['horse_mean_vs_standard'] - \n",
    "                                             test_12['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_12.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_12.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1b, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_1b = ((test_12['horse_top_qtr_vs_standard'] - \n",
    "                                             test_12['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_12.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_12.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1c, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_1c = ((test_12['horse_max_vs_standard'] - \n",
    "                                             test_12['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_12.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_12.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1d, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_1d = ((test_12['horse_min_vs_standard'] - \n",
    "                                             test_12['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_12.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_12.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_1e, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_1e = ((test_12['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_12['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_12.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_12.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_12 = test_12.assign(feature_3 = ((test_12['horse_median_vs_standard_3'] - \n",
    "                                             test_12['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_12.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_12.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3a, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_3a = ((test_12['horse_mean_vs_standard_3'] - \n",
    "                                             test_12['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_12.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_12.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3b, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_3b = ((test_12['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_12['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_12.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_12.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3c, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_3c = ((test_12['horse_max_vs_standard_3'] - \n",
    "                                             test_12['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_12.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_12.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3d, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_3d = ((test_12['horse_min_vs_standard_3'] - \n",
    "                                             test_12['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_12.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_12.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_12.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_3e, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_12 = test_12.assign(feature_3e = ((test_12['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_12['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_12.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_12 = pd.merge(test_12, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_12.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_12.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, temp_5, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_12 = test_12.assign(jock_pct_race_f5 = \n",
    "               ((test_12['jock_pct'] - test_12['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_12.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_12 = pd.merge(test_12, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_12.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_12.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_12 = pd.merge(test_12, temp_6, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_12 = test_12.assign(trainer_pct_race_f6 = \n",
    "               ((test_12['trainer_pct'] - test_12['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_12 = test_12.assign(jock_trainer_combo = (test_12['trainer'] + test_12['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_12.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_12 = pd.merge(test_12, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_12.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_12.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_12 = pd.merge(test_12, temp_7, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_12 = test_12.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_12['jock_trainer_win_pct'] - test_12['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_12.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_12 = pd.merge(test_12, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_12.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_12.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_12 = pd.merge(test_12, temp_8, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_12 = test_12.assign(bar_win_race_f8 = \n",
    "               ((test_12['bar_win_mean'] - test_12['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_12 = test_12.sort_values(by=['indexing'], ascending =True)\n",
    "test_12 = test_12.reset_index()\n",
    "test_12 = test_12.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_12[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_12[['STORMY VIEW']].head()\n",
    "\n",
    "#test_12.loc[(test_12['date'] == '2019-07-07') & (test_12['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_12[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_12['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_12[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_12 = test_12.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_12.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, race_lbw_max, on='indexing_date_race')\n",
    "test_12.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_12 = test_12.sort_values(by=['indexing'], ascending =True)\n",
    "test_12 = test_12.reset_index()\n",
    "test_12 = test_12.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_12 = test_12.assign(race_lbw_pred = ((test_12['lbw_pred'] - test_12['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_12.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_12['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_12['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_12.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_12 = pd.merge(test_12, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_12.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_12 = test_12.assign(race_prob_pred = ((test_12['prob_pred'] / test_12['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_12 = test_12.assign(race_win_div_pred = ((5 / ((test_12['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_12.loc[(test_12['date'] == '2019-07-07') & (test_12['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_12[test_12.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True)  \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_12 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2</td>\n",
       "      <td>CHARMING DIAMOND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>3</td>\n",
       "      <td>BOOM SHAKALAKA</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.562500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>1</td>\n",
       "      <td>ONE WORLD</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2</td>\n",
       "      <td>AMAZING CHOICE</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>5</td>\n",
       "      <td>IMPLEMENT</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>12.937500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>7</td>\n",
       "      <td>THREEANDFOURPENCE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>GENTLEMEN AGREEMENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>-5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>LIM'S TORPEDO</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>3</td>\n",
       "      <td>OTTAWA</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>16.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>4</td>\n",
       "      <td>ADIPSON</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>5</td>\n",
       "      <td>ATHLETICA</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race           horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "11  2019-06-21     2     CHARMING DIAMOND  0.0           5.937500         12     -5    12.0          1\n",
       "25  2019-06-21     3       BOOM SHAKALAKA -0.3          13.562500         21     -5     0.5          0\n",
       "95  2019-06-28     1            ONE WORLD -4.1          11.250000         22     -5     0.5          0\n",
       "105 2019-06-28     2       AMAZING CHOICE -1.5          16.666667         19     -5     0.5          0\n",
       "142 2019-06-28     5            IMPLEMENT -1.1          12.937500         20     -5     0.5          0\n",
       "163 2019-06-28     7    THREEANDFOURPENCE  0.0          18.000000         23     -5    23.0          1\n",
       "186 2019-06-30     1  GENTLEMEN AGREEMENT  0.0          13.000000         14     -5    14.0          1\n",
       "203 2019-06-30     2        LIM'S TORPEDO -1.2           5.812500         24     -5     0.5          0\n",
       "221 2019-06-30     3               OTTAWA -5.9          16.375000         18     -5     0.5          0\n",
       "226 2019-06-30     4              ADIPSON -0.8           9.062500         12     -5     0.5          0\n",
       "239 2019-06-30     5            ATHLETICA -0.4          17.000000         19     -5     0.5          0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_11 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_11.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_surf_dist')\n",
    "train_11.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_11 = train_11.assign(lengths_vs_standard_1 = \n",
    "                           ((train_11['avg_km_hr_2'] - train_11['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_11['lengths_vs_standard_1'].groupby(train_11['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_11 = pd.merge(train_11, temp, on='horse_name')\n",
    "train_11.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_11.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_11.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_11.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_11.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_11.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_11.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_11.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_1 = ((train_11['horse_median_vs_standard'] - train_11['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_1a = ((train_11['horse_mean_vs_standard'] - train_11['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_1b = ((train_11['horse_top_qtr_vs_standard'] - train_11['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_1c = ((train_11['horse_max_vs_standard'] - train_11['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_11 = train_11.assign(feature_1d = ((train_11['horse_min_vs_standard'] - train_11['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_11 = train_11.assign(feature_1e = ((train_11['horse_bot_qtr_vs_standard'] - train_11['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_11.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_11.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_surf_dist')\n",
    "train_11.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_11 = train_11.assign(lengths_vs_standard_3 = (((((train_11['l100m_km_hr_2'])+(train_11['avg_km_hr_2']))/2) \n",
    "                                         - train_11['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_11['lengths_vs_standard_3'].groupby(train_11['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_11 = pd.merge(train_11, temp, on='horse_name')\n",
    "train_11.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_11.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_11.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_11.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_11.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_11.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_11.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_11.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_3 = ((train_11['horse_median_vs_standard_3'] - train_11['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_3a = ((train_11['horse_mean_vs_standard_3'] - train_11['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_3b = ((train_11['horse_top_qtr_vs_standard_3'] - train_11['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_11 = train_11.assign(feature_3c = ((train_11['horse_max_vs_standard_3'] - train_11['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_11 = train_11.assign(feature_3d = ((train_11['horse_min_vs_standard_3'] - train_11['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_11.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, temp, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_11 = train_11.assign(feature_3e = ((train_11['horse_bot_qtr_vs_standard_3'] - train_11['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "train_11 = train_11.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_11[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_11 = pd.merge(train_11, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_11.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, jockey_pct_race, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_11 = train_11.assign(jock_pct_race_f5 = \n",
    "               ((train_11['jock_pct'] - train_11['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_11[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_11 = pd.merge(train_11, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_11.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, trainer_pct_race, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_11 = train_11.assign(trainer_pct_race_f6 = \n",
    "               ((train_11['trainer_pct'] - train_11['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_11 = train_11.assign(jock_trainer_combo = (train_11['trainer'] + train_11['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_11[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_11 = pd.merge(train_11, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_11.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_11 = train_11.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_11['jock_trainer_win_pct'] - train_11['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_11.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_11 = pd.merge(train_11, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_11.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_11 = pd.merge(train_11, bar_win_max_race, on='indexing_date_race')\n",
    "train_11.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_11 = train_11.assign(bar_win_race_f8 = ((train_11['bar_win_mean'] - train_11['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_11 = train_11.sort_values(by=['indexing'], ascending =True)\n",
    "train_11 = train_11.reset_index()\n",
    "train_11 = train_11.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_11.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_11.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_11 = test_11.assign(feature_1 = ((test_11['horse_median_vs_standard'] - \n",
    "                                             test_11['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_11.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_11.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1a, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_1a = ((test_11['horse_mean_vs_standard'] - \n",
    "                                             test_11['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_11.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_11.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1b, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_1b = ((test_11['horse_top_qtr_vs_standard'] - \n",
    "                                             test_11['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_11.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_11.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1c, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_1c = ((test_11['horse_max_vs_standard'] - \n",
    "                                             test_11['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_11.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_11.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1d, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_1d = ((test_11['horse_min_vs_standard'] - \n",
    "                                             test_11['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_11.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_11.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_1e, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_1e = ((test_11['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_11['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_11.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_11.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_11 = test_11.assign(feature_3 = ((test_11['horse_median_vs_standard_3'] - \n",
    "                                             test_11['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_11.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_11.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3a, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_3a = ((test_11['horse_mean_vs_standard_3'] - \n",
    "                                             test_11['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_11.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_11.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3b, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_3b = ((test_11['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_11['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_11.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_11.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3c, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_3c = ((test_11['horse_max_vs_standard_3'] - \n",
    "                                             test_11['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_11.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_11.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3d, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_3d = ((test_11['horse_min_vs_standard_3'] - \n",
    "                                             test_11['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_11.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_11.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_11.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_3e, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_11 = test_11.assign(feature_3e = ((test_11['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_11['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_11.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_11 = pd.merge(test_11, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_11.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_11.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, temp_5, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_11 = test_11.assign(jock_pct_race_f5 = \n",
    "               ((test_11['jock_pct'] - test_11['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_11.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_11 = pd.merge(test_11, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_11.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_11.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_11 = pd.merge(test_11, temp_6, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_11 = test_11.assign(trainer_pct_race_f6 = \n",
    "               ((test_11['trainer_pct'] - test_11['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_11 = test_11.assign(jock_trainer_combo = (test_11['trainer'] + test_11['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_11.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_11 = pd.merge(test_11, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_11.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_11.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_11 = pd.merge(test_11, temp_7, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_11 = test_11.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_11['jock_trainer_win_pct'] - test_11['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_11.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_11 = pd.merge(test_11, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_11.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_11.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_11 = pd.merge(test_11, temp_8, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_11 = test_11.assign(bar_win_race_f8 = \n",
    "               ((test_11['bar_win_mean'] - test_11['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_11 = test_11.sort_values(by=['indexing'], ascending =True)\n",
    "test_11 = test_11.reset_index()\n",
    "test_11 = test_11.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_11[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_11[['STORMY VIEW']].head()\n",
    "\n",
    "#test_11.loc[(test_11['date'] == '2019-07-07') & (test_11['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_11[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_11['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_11[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_11 = test_11.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_11.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, race_lbw_max, on='indexing_date_race')\n",
    "test_11.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_11 = test_11.sort_values(by=['indexing'], ascending =True)\n",
    "test_11 = test_11.reset_index()\n",
    "test_11 = test_11.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_11 = test_11.assign(race_lbw_pred = ((test_11['lbw_pred'] - test_11['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_11.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_11['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_11['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_11.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_11 = pd.merge(test_11, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_11.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_11 = test_11.assign(race_prob_pred = ((test_11['prob_pred'] / test_11['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_11 = test_11.assign(race_win_div_pred = ((5 / ((test_11['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_11.loc[(test_11['date'] == '2019-07-07') & (test_11['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_11[test_11.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True)   \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_11 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>4</td>\n",
       "      <td>GEB WARRIOR</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>4</td>\n",
       "      <td>WHITE TRUFFLE</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>19.538462</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>7</td>\n",
       "      <td>AUGUSTANO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.928571</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>8</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.687500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>PEGASUS JUNIOR</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>2</td>\n",
       "      <td>VULCAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>3</td>\n",
       "      <td>ADMIRAL WINSTON</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>4</td>\n",
       "      <td>FEDERATION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>5</td>\n",
       "      <td>IMPLEMENT</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>6</td>\n",
       "      <td>SPECIAL RAIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.812500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>FOREVER WIN</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>3</td>\n",
       "      <td>SMILING PROUD</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>18.812500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>8</td>\n",
       "      <td>JULIUS CAESAR</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>2</td>\n",
       "      <td>ON LINE</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>6.687500</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>3</td>\n",
       "      <td>COUSTEAU</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>7</td>\n",
       "      <td>WIND TRAIL</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.562500</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>9</td>\n",
       "      <td>DRAGON DUKE</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race       horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "42  2019-06-07     4      GEB WARRIOR -0.3          15.875000         22     -5     0.5          0\n",
       "44  2019-06-07     4    WHITE TRUFFLE -2.1          19.538462         22     -5     0.5          0\n",
       "75  2019-06-07     7        AUGUSTANO  0.0          21.928571         27     -5    27.0          1\n",
       "87  2019-06-07     8     LIM'S KNIGHT  0.0          16.687500         24     -5    24.0          1\n",
       "104 2019-06-09     1   PEGASUS JUNIOR -3.6          20.312500         27     -5     0.5          0\n",
       "111 2019-06-09     2           VULCAN  0.0           5.750000          8     -5     8.0          1\n",
       "125 2019-06-09     3  ADMIRAL WINSTON -2.8           6.187500         18     -5     0.5          0\n",
       "135 2019-06-09     4       FEDERATION  0.0           9.562500         13     -5    13.0          1\n",
       "148 2019-06-09     5        IMPLEMENT -1.8           6.562500         23     -5     0.5          0\n",
       "160 2019-06-09     6     SPECIAL RAIN  0.0          17.812500         23     -5    23.0          1\n",
       "238 2019-06-14     2      FOREVER WIN -2.3          10.437500         13     -5     0.5          0\n",
       "253 2019-06-14     3    SMILING PROUD -7.4          18.812500         22     -5     0.5          0\n",
       "314 2019-06-14     8    JULIUS CAESAR -6.9          22.250000         23     -5     0.5          0\n",
       "336 2019-06-15     2          ON LINE -1.1           6.687500         10     -5     0.5          0\n",
       "346 2019-06-15     3         COUSTEAU -2.6          22.250000         23     -5     0.5          0\n",
       "392 2019-06-15     7       WIND TRAIL -1.0          13.562500         27     -5     0.5          0\n",
       "420 2019-06-15     9      DRAGON DUKE -1.6          12.312500         27     -5     0.5          0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_10 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_10.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_surf_dist')\n",
    "train_10.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_10 = train_10.assign(lengths_vs_standard_1 = \n",
    "                           ((train_10['avg_km_hr_2'] - train_10['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_10['lengths_vs_standard_1'].groupby(train_10['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_10 = pd.merge(train_10, temp, on='horse_name')\n",
    "train_10.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_10.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_10.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_10.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_10.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_10.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_10.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_10.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_1 = ((train_10['horse_median_vs_standard'] - train_10['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_1a = ((train_10['horse_mean_vs_standard'] - train_10['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_1b = ((train_10['horse_top_qtr_vs_standard'] - train_10['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_1c = ((train_10['horse_max_vs_standard'] - train_10['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_10 = train_10.assign(feature_1d = ((train_10['horse_min_vs_standard'] - train_10['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_10 = train_10.assign(feature_1e = ((train_10['horse_bot_qtr_vs_standard'] - train_10['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_10.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_10.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_surf_dist')\n",
    "train_10.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_10 = train_10.assign(lengths_vs_standard_3 = (((((train_10['l100m_km_hr_2'])+(train_10['avg_km_hr_2']))/2) \n",
    "                                         - train_10['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_10['lengths_vs_standard_3'].groupby(train_10['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_10 = pd.merge(train_10, temp, on='horse_name')\n",
    "train_10.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_10.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_10.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_10.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_10.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_10.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_10.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_10.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_3 = ((train_10['horse_median_vs_standard_3'] - train_10['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_3a = ((train_10['horse_mean_vs_standard_3'] - train_10['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_3b = ((train_10['horse_top_qtr_vs_standard_3'] - train_10['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_10 = train_10.assign(feature_3c = ((train_10['horse_max_vs_standard_3'] - train_10['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_10 = train_10.assign(feature_3d = ((train_10['horse_min_vs_standard_3'] - train_10['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_10.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, temp, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_10 = train_10.assign(feature_3e = ((train_10['horse_bot_qtr_vs_standard_3'] - train_10['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "train_10 = train_10.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_10[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_10 = pd.merge(train_10, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_10.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, jockey_pct_race, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_10 = train_10.assign(jock_pct_race_f5 = \n",
    "               ((train_10['jock_pct'] - train_10['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_10[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_10 = pd.merge(train_10, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_10.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, trainer_pct_race, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_10 = train_10.assign(trainer_pct_race_f6 = \n",
    "               ((train_10['trainer_pct'] - train_10['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_10 = train_10.assign(jock_trainer_combo = (train_10['trainer'] + train_10['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_10[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_10 = pd.merge(train_10, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_10.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_10 = train_10.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_10['jock_trainer_win_pct'] - train_10['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_10.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_10 = pd.merge(train_10, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_10.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_10 = pd.merge(train_10, bar_win_max_race, on='indexing_date_race')\n",
    "train_10.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_10 = train_10.assign(bar_win_race_f8 = ((train_10['bar_win_mean'] - train_10['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_10 = train_10.sort_values(by=['indexing'], ascending =True)\n",
    "train_10 = train_10.reset_index()\n",
    "train_10 = train_10.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_10.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_10.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_10 = test_10.assign(feature_1 = ((test_10['horse_median_vs_standard'] - \n",
    "                                             test_10['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_10.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_10.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1a, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_1a = ((test_10['horse_mean_vs_standard'] - \n",
    "                                             test_10['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_10.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_10.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1b, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_1b = ((test_10['horse_top_qtr_vs_standard'] - \n",
    "                                             test_10['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_10.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_10.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1c, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_1c = ((test_10['horse_max_vs_standard'] - \n",
    "                                             test_10['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_10.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_10.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1d, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_1d = ((test_10['horse_min_vs_standard'] - \n",
    "                                             test_10['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_10.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_10.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_1e, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_1e = ((test_10['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_10['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_10.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_10.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_10 = test_10.assign(feature_3 = ((test_10['horse_median_vs_standard_3'] - \n",
    "                                             test_10['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_10.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_10.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3a, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_3a = ((test_10['horse_mean_vs_standard_3'] - \n",
    "                                             test_10['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_10.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_10.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3b, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_3b = ((test_10['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_10['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_10.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_10.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3c, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_3c = ((test_10['horse_max_vs_standard_3'] - \n",
    "                                             test_10['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_10.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_10.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3d, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_3d = ((test_10['horse_min_vs_standard_3'] - \n",
    "                                             test_10['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_10.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_10.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_10.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_3e, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_10 = test_10.assign(feature_3e = ((test_10['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_10['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_10.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_10 = pd.merge(test_10, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_10.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_10.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, temp_5, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_10 = test_10.assign(jock_pct_race_f5 = \n",
    "               ((test_10['jock_pct'] - test_10['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_10.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_10 = pd.merge(test_10, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_10.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_10.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_10 = pd.merge(test_10, temp_6, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_10 = test_10.assign(trainer_pct_race_f6 = \n",
    "               ((test_10['trainer_pct'] - test_10['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_10 = test_10.assign(jock_trainer_combo = (test_10['trainer'] + test_10['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_10.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_10 = pd.merge(test_10, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_10.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_10.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_10 = pd.merge(test_10, temp_7, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_10 = test_10.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_10['jock_trainer_win_pct'] - test_10['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_10.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_10 = pd.merge(test_10, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_10.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_10.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_10 = pd.merge(test_10, temp_8, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_10 = test_10.assign(bar_win_race_f8 = \n",
    "               ((test_10['bar_win_mean'] - test_10['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_10 = test_10.sort_values(by=['indexing'], ascending =True)\n",
    "test_10 = test_10.reset_index()\n",
    "test_10 = test_10.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_10[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_10[['STORMY VIEW']].head()\n",
    "\n",
    "#test_10.loc[(test_10['date'] == '2019-07-07') & (test_10['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_10[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_10['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_10[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_10 = test_10.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_10.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, race_lbw_max, on='indexing_date_race')\n",
    "test_10.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_10 = test_10.sort_values(by=['indexing'], ascending =True)\n",
    "test_10 = test_10.reset_index()\n",
    "test_10 = test_10.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_10 = test_10.assign(race_lbw_pred = ((test_10['lbw_pred'] - test_10['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_10.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_10['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_10['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_10.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_10 = pd.merge(test_10, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_10.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_10 = test_10.assign(race_prob_pred = ((test_10['prob_pred'] / test_10['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_10 = test_10.assign(race_win_div_pred = ((5 / ((test_10['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_10.loc[(test_10['date'] == '2019-07-07') & (test_10['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_10[test_10.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True)   \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_10 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>1</td>\n",
       "      <td>AABIR</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>25.3000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>3</td>\n",
       "      <td>WIND OF LIBERTY</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>17.6875</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>4</td>\n",
       "      <td>CLARTON STAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.4375</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>5</td>\n",
       "      <td>WELL DESERVED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>7</td>\n",
       "      <td>IMPLEMENT</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.5000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>3</td>\n",
       "      <td>BIG HEARTED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6875</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>7</td>\n",
       "      <td>SUGARTIME JAZZ</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>16.5625</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>5</td>\n",
       "      <td>BIRAZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1250</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>6</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>10</td>\n",
       "      <td>ELITE POWER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8125</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>ONE WORLD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.5625</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>4</td>\n",
       "      <td>RAPIDASH</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>5.7500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>6</td>\n",
       "      <td>VENUS DE MILO</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORPIO</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>16.6000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>5</td>\n",
       "      <td>WIJAYA</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>9</td>\n",
       "      <td>AUGUSTUS</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>12.5625</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>10</td>\n",
       "      <td>JULIUS CAESAR</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>15.1250</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race       horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "1   2019-05-17     1            AABIR -0.8            25.3000         27     -5     0.5          0\n",
       "26  2019-05-17     3  WIND OF LIBERTY -3.6            17.6875         22     -5     0.5          0\n",
       "34  2019-05-17     4     CLARTON STAR  0.0            16.4375         19     -5    19.0          1\n",
       "45  2019-05-17     5    WELL DESERVED  0.0            14.5000         26     -5    26.0          1\n",
       "64  2019-05-17     7        IMPLEMENT -0.5             8.5000         27     -5     0.5          0\n",
       "111 2019-05-19     3      BIG HEARTED  0.0             5.6875         10     -5    10.0          1\n",
       "159 2019-05-19     7   SUGARTIME JAZZ -0.5            16.5625         24     -5     0.5          0\n",
       "257 2019-05-25     5            BIRAZ  0.0            16.1250         20     -5    20.0          1\n",
       "274 2019-05-25     6     LIM'S KNIGHT -2.7            14.0000         19     -5     0.5          0\n",
       "321 2019-05-25    10      ELITE POWER  0.0            13.8125         21     -5    21.0          1\n",
       "330 2019-05-31     1        ONE WORLD  0.0             7.5625         12     -5    12.0          1\n",
       "367 2019-05-31     4         RAPIDASH -2.5             5.7500         20     -5     0.5          0\n",
       "396 2019-05-31     6    VENUS DE MILO -6.7            14.2500         19     -5     0.5          0\n",
       "431 2019-06-01     1          SCORPIO -4.4            16.6000         26     -5     0.5          0\n",
       "474 2019-06-01     5           WIJAYA -1.5            11.5000         16     -5     0.5          0\n",
       "519 2019-06-01     9         AUGUSTUS -0.5            12.5625         18     -5     0.5          0\n",
       "533 2019-06-01    10    JULIUS CAESAR -7.6            15.1250         22     -5     0.5          0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_9 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_9.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_surf_dist')\n",
    "train_9.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_9 = train_9.assign(lengths_vs_standard_1 = \n",
    "                           ((train_9['avg_km_hr_2'] - train_9['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_9['lengths_vs_standard_1'].groupby(train_9['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_9 = pd.merge(train_9, temp, on='horse_name')\n",
    "train_9.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_9.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_9.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_9.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_9.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_9.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_9.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_9.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_1 = ((train_9['horse_median_vs_standard'] - train_9['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_1a = ((train_9['horse_mean_vs_standard'] - train_9['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_1b = ((train_9['horse_top_qtr_vs_standard'] - train_9['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_1c = ((train_9['horse_max_vs_standard'] - train_9['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_9 = train_9.assign(feature_1d = ((train_9['horse_min_vs_standard'] - train_9['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_9 = train_9.assign(feature_1e = ((train_9['horse_bot_qtr_vs_standard'] - train_9['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_9.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_9.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_surf_dist')\n",
    "train_9.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_9 = train_9.assign(lengths_vs_standard_3 = (((((train_9['l100m_km_hr_2'])+(train_9['avg_km_hr_2']))/2) \n",
    "                                         - train_9['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_9['lengths_vs_standard_3'].groupby(train_9['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_9 = pd.merge(train_9, temp, on='horse_name')\n",
    "train_9.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_9.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_9.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_9.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_9.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_9.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_9.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_9.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_3 = ((train_9['horse_median_vs_standard_3'] - train_9['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_3a = ((train_9['horse_mean_vs_standard_3'] - train_9['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_3b = ((train_9['horse_top_qtr_vs_standard_3'] - train_9['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_9 = train_9.assign(feature_3c = ((train_9['horse_max_vs_standard_3'] - train_9['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_9 = train_9.assign(feature_3d = ((train_9['horse_min_vs_standard_3'] - train_9['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_9.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, temp, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_9 = train_9.assign(feature_3e = ((train_9['horse_bot_qtr_vs_standard_3'] - train_9['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "train_9 = train_9.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_9[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_9 = pd.merge(train_9, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_9.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, jockey_pct_race, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_9 = train_9.assign(jock_pct_race_f5 = \n",
    "               ((train_9['jock_pct'] - train_9['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_9[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_9 = pd.merge(train_9, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_9.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, trainer_pct_race, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_9 = train_9.assign(trainer_pct_race_f6 = \n",
    "               ((train_9['trainer_pct'] - train_9['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_9 = train_9.assign(jock_trainer_combo = (train_9['trainer'] + train_9['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_9[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_9 = pd.merge(train_9, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_9.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_9 = train_9.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_9['jock_trainer_win_pct'] - train_9['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_9.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_9 = pd.merge(train_9, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_9.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_9 = pd.merge(train_9, bar_win_max_race, on='indexing_date_race')\n",
    "train_9.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_9 = train_9.assign(bar_win_race_f8 = ((train_9['bar_win_mean'] - train_9['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_9 = train_9.sort_values(by=['indexing'], ascending =True)\n",
    "train_9 = train_9.reset_index()\n",
    "train_9 = train_9.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_9.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_9.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_9 = test_9.assign(feature_1 = ((test_9['horse_median_vs_standard'] - \n",
    "                                             test_9['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_9.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_9.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1a, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_1a = ((test_9['horse_mean_vs_standard'] - \n",
    "                                             test_9['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_9.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_9.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1b, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_1b = ((test_9['horse_top_qtr_vs_standard'] - \n",
    "                                             test_9['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_9.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_9.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1c, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_1c = ((test_9['horse_max_vs_standard'] - \n",
    "                                             test_9['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_9.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_9.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1d, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_1d = ((test_9['horse_min_vs_standard'] - \n",
    "                                             test_9['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_9.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_9.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_1e, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_1e = ((test_9['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_9['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_9.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_9.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_9 = test_9.assign(feature_3 = ((test_9['horse_median_vs_standard_3'] - \n",
    "                                             test_9['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_9.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_9.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3a, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_3a = ((test_9['horse_mean_vs_standard_3'] - \n",
    "                                             test_9['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_9.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_9.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3b, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_3b = ((test_9['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_9['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_9.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_9.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3c, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_3c = ((test_9['horse_max_vs_standard_3'] - \n",
    "                                             test_9['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_9.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_9.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3d, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_3d = ((test_9['horse_min_vs_standard_3'] - \n",
    "                                             test_9['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_9.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_9.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_9.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_3e, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_9 = test_9.assign(feature_3e = ((test_9['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_9['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_9.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_9 = pd.merge(test_9, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_9.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_9.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, temp_5, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_9 = test_9.assign(jock_pct_race_f5 = \n",
    "               ((test_9['jock_pct'] - test_9['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_9.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_9 = pd.merge(test_9, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_9.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_9.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_9 = pd.merge(test_9, temp_6, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_9 = test_9.assign(trainer_pct_race_f6 = \n",
    "               ((test_9['trainer_pct'] - test_9['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_9 = test_9.assign(jock_trainer_combo = (test_9['trainer'] + test_9['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_9.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_9 = pd.merge(test_9, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_9.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_9.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_9 = pd.merge(test_9, temp_7, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_9 = test_9.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_9['jock_trainer_win_pct'] - test_9['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_9.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_9 = pd.merge(test_9, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_9.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_9.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_9 = pd.merge(test_9, temp_8, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_9 = test_9.assign(bar_win_race_f8 = \n",
    "               ((test_9['bar_win_mean'] - test_9['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_9 = test_9.sort_values(by=['indexing'], ascending =True)\n",
    "test_9 = test_9.reset_index()\n",
    "test_9 = test_9.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_9[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_9[['STORMY VIEW']].head()\n",
    "\n",
    "#test_9.loc[(test_9['date'] == '2019-07-07') & (test_9['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_9[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_9['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_9[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_9 = test_9.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_9.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, race_lbw_max, on='indexing_date_race')\n",
    "test_9.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_9 = test_9.sort_values(by=['indexing'], ascending =True)\n",
    "test_9 = test_9.reset_index()\n",
    "test_9 = test_9.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_9 = test_9.assign(race_lbw_pred = ((test_9['lbw_pred'] - test_9['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_9.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_9['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_9['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_9.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_9 = pd.merge(test_9, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_9.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_9 = test_9.assign(race_prob_pred = ((test_9['prob_pred'] / test_9['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_9 = test_9.assign(race_win_div_pred = ((5 / ((test_9['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_9.loc[(test_9['date'] == '2019-07-07') & (test_9['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_9[test_9.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_9 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>2</td>\n",
       "      <td>LIM'S PASSION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3750</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>4</td>\n",
       "      <td>AABIR</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>5</td>\n",
       "      <td>SUPER SIX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.4000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>5</td>\n",
       "      <td>YULONG FAST STEED</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>2</td>\n",
       "      <td>JULIUS CAESAR</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>15.1250</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>3</td>\n",
       "      <td>JUPITER DRAGON</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>11.8125</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>4</td>\n",
       "      <td>SIAM ROYAL ORCHID</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>10.1250</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>5</td>\n",
       "      <td>SUPER WIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6250</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>10</td>\n",
       "      <td>FAME STAR</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>15.8125</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>1</td>\n",
       "      <td>PAPERBACK TROOPER</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>9.8750</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>4</td>\n",
       "      <td>PRIME TIME</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>9.5625</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>5</td>\n",
       "      <td>WHITE TRUFFLE</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>7.0625</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>2</td>\n",
       "      <td>PAKATAN WARRIOR</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>7.3750</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>3</td>\n",
       "      <td>CIRCUIT MISSION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8750</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>6</td>\n",
       "      <td>NEO'S CLASSIC</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>11.6250</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>10</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>17.6875</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race         horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "14  2019-05-03     2      LIM'S PASSION  0.0            11.3750         18     -5    18.0          1\n",
       "47  2019-05-03     4              AABIR -3.1             7.5000         20     -5     0.5          0\n",
       "53  2019-05-03     5          SUPER SIX  0.0            18.4000         26     -5    26.0          1\n",
       "55  2019-05-03     5  YULONG FAST STEED -3.8            11.5000         20     -5     0.5          0\n",
       "134 2019-05-05     2      JULIUS CAESAR -1.4            15.1250         22     -5     0.5          0\n",
       "150 2019-05-05     3     JUPITER DRAGON -7.8            11.8125         18     -5     0.5          0\n",
       "157 2019-05-05     4  SIAM ROYAL ORCHID -0.6            10.1250         17     -5     0.5          0\n",
       "169 2019-05-05     5          SUPER WIN  0.0            13.6250         19     -5    19.0          1\n",
       "234 2019-05-05    10          FAME STAR -2.8            15.8125         16     -5     0.5          0\n",
       "248 2019-05-10     1  PAPERBACK TROOPER -1.5             9.8750         22     -5     0.5          0\n",
       "287 2019-05-10     4         PRIME TIME -4.9             9.5625         11     -5     0.5          0\n",
       "297 2019-05-10     5      WHITE TRUFFLE -0.6             7.0625         11     -5     0.5          0\n",
       "363 2019-05-12     2    PAKATAN WARRIOR -6.3             7.3750         24     -5     0.5          0\n",
       "368 2019-05-12     3    CIRCUIT MISSION  0.0            13.8750         19     -5    19.0          1\n",
       "407 2019-05-12     6      NEO'S CLASSIC -4.7            11.6250         25     -5     0.5          0\n",
       "447 2019-05-12    10       LIM'S KNIGHT -4.8            17.6875         23     -5     0.5          0"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_8 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_8.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_surf_dist')\n",
    "train_8.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_8 = train_8.assign(lengths_vs_standard_1 = \n",
    "                           ((train_8['avg_km_hr_2'] - train_8['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_8['lengths_vs_standard_1'].groupby(train_8['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_8 = pd.merge(train_8, temp, on='horse_name')\n",
    "train_8.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_8.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_8.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_8.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_8.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_8.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_8.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_8.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_1 = ((train_8['horse_median_vs_standard'] - train_8['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_1a = ((train_8['horse_mean_vs_standard'] - train_8['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_1b = ((train_8['horse_top_qtr_vs_standard'] - train_8['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_1c = ((train_8['horse_max_vs_standard'] - train_8['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_8 = train_8.assign(feature_1d = ((train_8['horse_min_vs_standard'] - train_8['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_8 = train_8.assign(feature_1e = ((train_8['horse_bot_qtr_vs_standard'] - train_8['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_8.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_8.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_surf_dist')\n",
    "train_8.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_8 = train_8.assign(lengths_vs_standard_3 = (((((train_8['l100m_km_hr_2'])+(train_8['avg_km_hr_2']))/2) \n",
    "                                         - train_8['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_8['lengths_vs_standard_3'].groupby(train_8['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_8 = pd.merge(train_8, temp, on='horse_name')\n",
    "train_8.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_8.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_8.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_8.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_8.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_8.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_8.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_8.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_3 = ((train_8['horse_median_vs_standard_3'] - train_8['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_3a = ((train_8['horse_mean_vs_standard_3'] - train_8['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_3b = ((train_8['horse_top_qtr_vs_standard_3'] - train_8['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_8 = train_8.assign(feature_3c = ((train_8['horse_max_vs_standard_3'] - train_8['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_8 = train_8.assign(feature_3d = ((train_8['horse_min_vs_standard_3'] - train_8['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_8.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, temp, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_8 = train_8.assign(feature_3e = ((train_8['horse_bot_qtr_vs_standard_3'] - train_8['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "train_8 = train_8.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_8[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_8 = pd.merge(train_8, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_8.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, jockey_pct_race, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_8 = train_8.assign(jock_pct_race_f5 = \n",
    "               ((train_8['jock_pct'] - train_8['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_8[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_8 = pd.merge(train_8, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_8.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, trainer_pct_race, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_8 = train_8.assign(trainer_pct_race_f6 = \n",
    "               ((train_8['trainer_pct'] - train_8['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_8 = train_8.assign(jock_trainer_combo = (train_8['trainer'] + train_8['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_8[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_8 = pd.merge(train_8, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_8.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_8 = train_8.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_8['jock_trainer_win_pct'] - train_8['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_8.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_8 = pd.merge(train_8, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_8.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_8 = pd.merge(train_8, bar_win_max_race, on='indexing_date_race')\n",
    "train_8.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_8 = train_8.assign(bar_win_race_f8 = ((train_8['bar_win_mean'] - train_8['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_8 = train_8.sort_values(by=['indexing'], ascending =True)\n",
    "train_8 = train_8.reset_index()\n",
    "train_8 = train_8.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_8.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_8.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_8 = test_8.assign(feature_1 = ((test_8['horse_median_vs_standard'] - \n",
    "                                             test_8['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_8.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_8.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1a, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_1a = ((test_8['horse_mean_vs_standard'] - \n",
    "                                             test_8['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_8.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_8.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1b, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_1b = ((test_8['horse_top_qtr_vs_standard'] - \n",
    "                                             test_8['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_8.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_8.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1c, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_1c = ((test_8['horse_max_vs_standard'] - \n",
    "                                             test_8['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_8.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_8.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1d, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_1d = ((test_8['horse_min_vs_standard'] - \n",
    "                                             test_8['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_8.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_8.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_1e, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_1e = ((test_8['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_8['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_8.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_8.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_8 = test_8.assign(feature_3 = ((test_8['horse_median_vs_standard_3'] - \n",
    "                                             test_8['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_8.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_8.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3a, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_3a = ((test_8['horse_mean_vs_standard_3'] - \n",
    "                                             test_8['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_8.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_8.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3b, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_3b = ((test_8['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_8['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_8.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_8.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3c, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_3c = ((test_8['horse_max_vs_standard_3'] - \n",
    "                                             test_8['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_8.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_8.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3d, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_3d = ((test_8['horse_min_vs_standard_3'] - \n",
    "                                             test_8['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_8.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_8.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_8.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_3e, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_8 = test_8.assign(feature_3e = ((test_8['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_8['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_8.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_8 = pd.merge(test_8, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_8.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_8.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, temp_5, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_8 = test_8.assign(jock_pct_race_f5 = \n",
    "               ((test_8['jock_pct'] - test_8['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_8.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_8 = pd.merge(test_8, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_8.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_8.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_8 = pd.merge(test_8, temp_6, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_8 = test_8.assign(trainer_pct_race_f6 = \n",
    "               ((test_8['trainer_pct'] - test_8['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_8 = test_8.assign(jock_trainer_combo = (test_8['trainer'] + test_8['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_8.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_8 = pd.merge(test_8, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_8.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_8.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_8 = pd.merge(test_8, temp_7, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_8 = test_8.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_8['jock_trainer_win_pct'] - test_8['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_8.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_8 = pd.merge(test_8, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_8.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_8.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_8 = pd.merge(test_8, temp_8, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_8 = test_8.assign(bar_win_race_f8 = \n",
    "               ((test_8['bar_win_mean'] - test_8['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_8 = test_8.sort_values(by=['indexing'], ascending =True)\n",
    "test_8 = test_8.reset_index()\n",
    "test_8 = test_8.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_8[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_8[['STORMY VIEW']].head()\n",
    "\n",
    "#test_8.loc[(test_8['date'] == '2019-07-07') & (test_8['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_8[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_8['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_8[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_8 = test_8.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_8.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, race_lbw_max, on='indexing_date_race')\n",
    "test_8.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_8 = test_8.sort_values(by=['indexing'], ascending =True)\n",
    "test_8 = test_8.reset_index()\n",
    "test_8 = test_8.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_8 = test_8.assign(race_lbw_pred = ((test_8['lbw_pred'] - test_8['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_8.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_8['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_8['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_8.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_8 = pd.merge(test_8, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_8.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_8 = test_8.assign(race_prob_pred = ((test_8['prob_pred'] / test_8['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_8 = test_8.assign(race_win_div_pred = ((5 / ((test_8['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_8.loc[(test_8['date'] == '2019-07-07') & (test_8['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_8[test_8.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_8 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>2</td>\n",
       "      <td>STAGESHOW</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>3</td>\n",
       "      <td>YULONG FAST STEED</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>19.769231</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>3</td>\n",
       "      <td>FIRST CHOICE</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>5</td>\n",
       "      <td>RED DAWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>6</td>\n",
       "      <td>ELITE POWER</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>20.937500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>8</td>\n",
       "      <td>BEBOP</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>2</td>\n",
       "      <td>LIM'S PASSION</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>13.125000</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>6</td>\n",
       "      <td>VENUS DE MILO</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>14.187500</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>8</td>\n",
       "      <td>NOWYOUSEE</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>16.875000</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>9</td>\n",
       "      <td>FULIFE KING</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>6</td>\n",
       "      <td>AUGUSTUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>7</td>\n",
       "      <td>GRATUS</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>12.937500</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>8</td>\n",
       "      <td>SACRED REBEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>9</td>\n",
       "      <td>BARTIMAEUS</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race         horse_name   lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "13  2019-04-19     2          STAGESHOW  -8.6          13.000000         27     -5     0.5          0\n",
       "23  2019-04-19     3  YULONG FAST STEED  -1.3          19.769231         24     -5     0.5          0\n",
       "25  2019-04-19     3       FIRST CHOICE  -5.3          16.062500         21     -5     0.5          0\n",
       "41  2019-04-19     5           RED DAWN   0.0          10.625000         25     -5    25.0          1\n",
       "54  2019-04-19     6        ELITE POWER  -1.4          20.937500         23     -5     0.5          0\n",
       "72  2019-04-19     8              BEBOP  -5.9          15.750000         23     -5     0.5          0\n",
       "104 2019-04-21     2      LIM'S PASSION  -2.6          13.125000         15     -5     0.5          0\n",
       "155 2019-04-21     6      VENUS DE MILO -10.7          14.187500         26     -5     0.5          0\n",
       "170 2019-04-21     8          NOWYOUSEE  -3.0          16.875000         17     -5     0.5          0\n",
       "180 2019-04-21     9        FULIFE KING  -1.1          15.125000         21     -5     0.5          0\n",
       "250 2019-04-26     6           AUGUSTUS   0.0          17.000000         23     -5    23.0          1\n",
       "267 2019-04-26     7             GRATUS  -4.5          12.937500         18     -5     0.5          0\n",
       "272 2019-04-26     8       SACRED REBEL   0.0           9.562500         19     -5    19.0          1\n",
       "287 2019-04-26     9         BARTIMAEUS  -2.3          17.250000         25     -5     0.5          0"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_7 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_7.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_surf_dist')\n",
    "train_7.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_7 = train_7.assign(lengths_vs_standard_1 = \n",
    "                           ((train_7['avg_km_hr_2'] - train_7['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_7['lengths_vs_standard_1'].groupby(train_7['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_7 = pd.merge(train_7, temp, on='horse_name')\n",
    "train_7.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_7.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_7.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_7.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_7.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_7.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_7.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_7.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_1 = ((train_7['horse_median_vs_standard'] - train_7['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_1a = ((train_7['horse_mean_vs_standard'] - train_7['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_1b = ((train_7['horse_top_qtr_vs_standard'] - train_7['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_1c = ((train_7['horse_max_vs_standard'] - train_7['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_7 = train_7.assign(feature_1d = ((train_7['horse_min_vs_standard'] - train_7['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_7 = train_7.assign(feature_1e = ((train_7['horse_bot_qtr_vs_standard'] - train_7['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_7.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_7.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_surf_dist')\n",
    "train_7.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_7 = train_7.assign(lengths_vs_standard_3 = (((((train_7['l100m_km_hr_2'])+(train_7['avg_km_hr_2']))/2) \n",
    "                                         - train_7['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_7['lengths_vs_standard_3'].groupby(train_7['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_7 = pd.merge(train_7, temp, on='horse_name')\n",
    "train_7.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_7.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_7.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_7.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_7.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_7.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_7.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_7.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_3 = ((train_7['horse_median_vs_standard_3'] - train_7['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_3a = ((train_7['horse_mean_vs_standard_3'] - train_7['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_3b = ((train_7['horse_top_qtr_vs_standard_3'] - train_7['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_7 = train_7.assign(feature_3c = ((train_7['horse_max_vs_standard_3'] - train_7['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_7 = train_7.assign(feature_3d = ((train_7['horse_min_vs_standard_3'] - train_7['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_7.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, temp, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_7 = train_7.assign(feature_3e = ((train_7['horse_bot_qtr_vs_standard_3'] - train_7['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "train_7 = train_7.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_7[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_7 = pd.merge(train_7, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_7.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, jockey_pct_race, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_7 = train_7.assign(jock_pct_race_f5 = \n",
    "               ((train_7['jock_pct'] - train_7['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_7[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_7 = pd.merge(train_7, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_7.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, trainer_pct_race, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_7 = train_7.assign(trainer_pct_race_f6 = \n",
    "               ((train_7['trainer_pct'] - train_7['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_7 = train_7.assign(jock_trainer_combo = (train_7['trainer'] + train_7['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_7[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_7 = pd.merge(train_7, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_7.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_7 = train_7.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_7['jock_trainer_win_pct'] - train_7['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_7.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_7 = pd.merge(train_7, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_7.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_7 = pd.merge(train_7, bar_win_max_race, on='indexing_date_race')\n",
    "train_7.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_7 = train_7.assign(bar_win_race_f8 = ((train_7['bar_win_mean'] - train_7['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_7 = train_7.sort_values(by=['indexing'], ascending =True)\n",
    "train_7 = train_7.reset_index()\n",
    "train_7 = train_7.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_7.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_7.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_7 = test_7.assign(feature_1 = ((test_7['horse_median_vs_standard'] - \n",
    "                                             test_7['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_7.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_7.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1a, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_1a = ((test_7['horse_mean_vs_standard'] - \n",
    "                                             test_7['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_7.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_7.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1b, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_1b = ((test_7['horse_top_qtr_vs_standard'] - \n",
    "                                             test_7['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_7.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_7.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1c, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_1c = ((test_7['horse_max_vs_standard'] - \n",
    "                                             test_7['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_7.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_7.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1d, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_1d = ((test_7['horse_min_vs_standard'] - \n",
    "                                             test_7['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_7.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_7.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_1e, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_1e = ((test_7['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_7['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_7.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_7.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_7 = test_7.assign(feature_3 = ((test_7['horse_median_vs_standard_3'] - \n",
    "                                             test_7['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_7.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_7.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3a, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_3a = ((test_7['horse_mean_vs_standard_3'] - \n",
    "                                             test_7['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_7.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_7.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3b, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_3b = ((test_7['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_7['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_7.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_7.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3c, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_3c = ((test_7['horse_max_vs_standard_3'] - \n",
    "                                             test_7['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_7.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_7.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3d, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_3d = ((test_7['horse_min_vs_standard_3'] - \n",
    "                                             test_7['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_7.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_7.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_7.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_3e, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_7 = test_7.assign(feature_3e = ((test_7['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_7['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_7.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_7 = pd.merge(test_7, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_7.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_7.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, temp_5, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_7 = test_7.assign(jock_pct_race_f5 = \n",
    "               ((test_7['jock_pct'] - test_7['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_7.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_7 = pd.merge(test_7, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_7.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_7.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_7 = pd.merge(test_7, temp_6, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_7 = test_7.assign(trainer_pct_race_f6 = \n",
    "               ((test_7['trainer_pct'] - test_7['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_7 = test_7.assign(jock_trainer_combo = (test_7['trainer'] + test_7['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_7.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_7 = pd.merge(test_7, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_7.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_7.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_7 = pd.merge(test_7, temp_7, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_7 = test_7.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_7['jock_trainer_win_pct'] - test_7['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_7.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_7 = pd.merge(test_7, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_7.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_7.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_7 = pd.merge(test_7, temp_8, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_7 = test_7.assign(bar_win_race_f8 = \n",
    "               ((test_7['bar_win_mean'] - test_7['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_7 = test_7.sort_values(by=['indexing'], ascending =True)\n",
    "test_7 = test_7.reset_index()\n",
    "test_7 = test_7.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_7[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_7[['STORMY VIEW']].head()\n",
    "\n",
    "#test_7.loc[(test_7['date'] == '2019-07-07') & (test_7['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_7[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_7['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_7[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_7 = test_7.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_7.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, race_lbw_max, on='indexing_date_race')\n",
    "test_7.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_7 = test_7.sort_values(by=['indexing'], ascending =True)\n",
    "test_7 = test_7.reset_index()\n",
    "test_7 = test_7.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_7 = test_7.assign(race_lbw_pred = ((test_7['lbw_pred'] - test_7['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_7.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_7['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_7['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_7.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_7 = pd.merge(test_7, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_7.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_7 = test_7.assign(race_prob_pred = ((test_7['prob_pred'] / test_7['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_7 = test_7.assign(race_win_div_pred = ((5 / ((test_7['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_7.loc[(test_7['date'] == '2019-07-07') & (test_7['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_7[test_7.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True)  \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_7 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>4</td>\n",
       "      <td>PAPERBACK TROOPER</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>16.687500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>8</td>\n",
       "      <td>SOUTHERN SPUR</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>TUN O'REILLY</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>13.625000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>2</td>\n",
       "      <td>YULONG EXPRESS</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>7</td>\n",
       "      <td>ARAMCO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>8</td>\n",
       "      <td>ELITE CONQUEST</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>10</td>\n",
       "      <td>IRONSIDE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>4</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>1</td>\n",
       "      <td>OPTIMUM STAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.857143</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2</td>\n",
       "      <td>YULONG EXPRESS</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>7.937500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>4</td>\n",
       "      <td>COLOUR PAINT</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>5</td>\n",
       "      <td>OTTAWA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.312500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>7</td>\n",
       "      <td>MO ALMIGHTY</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>9</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>9</td>\n",
       "      <td>SILENT FORCE</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race         horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "39  2019-04-05     4  PAPERBACK TROOPER -0.8          16.687500         23     -5     0.5          0\n",
       "100 2019-04-05     8      SOUTHERN SPUR -4.5          13.750000         18     -5     0.5          0\n",
       "112 2019-04-07     1       TUN O'REILLY -6.4          13.625000         25     -5     0.5          0\n",
       "123 2019-04-07     2     YULONG EXPRESS -2.1          21.000000         27     -5     0.5          0\n",
       "183 2019-04-07     7             ARAMCO  0.0          12.500000         20     -5    20.0          1\n",
       "206 2019-04-07     8     ELITE CONQUEST -2.5          12.500000         26     -5     0.5          0\n",
       "221 2019-04-07    10           IRONSIDE  0.0          24.437500         26     -5    26.0          1\n",
       "269 2019-04-12     4       LIM'S KNIGHT -0.5          10.937500         15     -5     0.5          0\n",
       "327 2019-04-14     1       OPTIMUM STAR  0.0          21.857143         22     -5    22.0          1\n",
       "341 2019-04-14     2     YULONG EXPRESS -1.5           7.937500         15     -5     0.5          0\n",
       "370 2019-04-14     4       COLOUR PAINT -5.0          11.375000         16     -5     0.5          0\n",
       "373 2019-04-14     5             OTTAWA  0.0          17.312500         21     -5    21.0          1\n",
       "398 2019-04-14     7        MO ALMIGHTY -3.0           7.750000          9     -5     0.5          0\n",
       "425 2019-04-14     9       SILENT FORCE -5.7          10.437500         22     -5     0.5          0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_6 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_6.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_surf_dist')\n",
    "train_6.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_6 = train_6.assign(lengths_vs_standard_1 = \n",
    "                           ((train_6['avg_km_hr_2'] - train_6['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_6['lengths_vs_standard_1'].groupby(train_6['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_6 = pd.merge(train_6, temp, on='horse_name')\n",
    "train_6.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_6.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_6.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_6.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_6.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_6.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_6.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_6.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_1 = ((train_6['horse_median_vs_standard'] - train_6['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_1a = ((train_6['horse_mean_vs_standard'] - train_6['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_1b = ((train_6['horse_top_qtr_vs_standard'] - train_6['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_1c = ((train_6['horse_max_vs_standard'] - train_6['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_6 = train_6.assign(feature_1d = ((train_6['horse_min_vs_standard'] - train_6['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_6 = train_6.assign(feature_1e = ((train_6['horse_bot_qtr_vs_standard'] - train_6['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_6.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_6.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_surf_dist')\n",
    "train_6.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_6 = train_6.assign(lengths_vs_standard_3 = (((((train_6['l100m_km_hr_2'])+(train_6['avg_km_hr_2']))/2) \n",
    "                                         - train_6['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_6['lengths_vs_standard_3'].groupby(train_6['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_6 = pd.merge(train_6, temp, on='horse_name')\n",
    "train_6.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_6.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_6.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_6.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_6.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_6.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_6.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_6.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_3 = ((train_6['horse_median_vs_standard_3'] - train_6['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_3a = ((train_6['horse_mean_vs_standard_3'] - train_6['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_3b = ((train_6['horse_top_qtr_vs_standard_3'] - train_6['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_6 = train_6.assign(feature_3c = ((train_6['horse_max_vs_standard_3'] - train_6['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_6 = train_6.assign(feature_3d = ((train_6['horse_min_vs_standard_3'] - train_6['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_6.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, temp, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_6 = train_6.assign(feature_3e = ((train_6['horse_bot_qtr_vs_standard_3'] - train_6['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "train_6 = train_6.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_6[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_6 = pd.merge(train_6, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_6.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, jockey_pct_race, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_6 = train_6.assign(jock_pct_race_f5 = \n",
    "               ((train_6['jock_pct'] - train_6['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_6[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_6 = pd.merge(train_6, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_6.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, trainer_pct_race, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_6 = train_6.assign(trainer_pct_race_f6 = \n",
    "               ((train_6['trainer_pct'] - train_6['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_6 = train_6.assign(jock_trainer_combo = (train_6['trainer'] + train_6['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_6[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_6 = pd.merge(train_6, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_6.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_6 = train_6.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_6['jock_trainer_win_pct'] - train_6['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_6.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_6 = pd.merge(train_6, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_6.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_6 = pd.merge(train_6, bar_win_max_race, on='indexing_date_race')\n",
    "train_6.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_6 = train_6.assign(bar_win_race_f8 = ((train_6['bar_win_mean'] - train_6['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_6 = train_6.sort_values(by=['indexing'], ascending =True)\n",
    "train_6 = train_6.reset_index()\n",
    "train_6 = train_6.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_6.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_6.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_6 = test_6.assign(feature_1 = ((test_6['horse_median_vs_standard'] - \n",
    "                                             test_6['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_6.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_6.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1a, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_1a = ((test_6['horse_mean_vs_standard'] - \n",
    "                                             test_6['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_6.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_6.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1b, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_1b = ((test_6['horse_top_qtr_vs_standard'] - \n",
    "                                             test_6['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_6.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_6.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1c, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_1c = ((test_6['horse_max_vs_standard'] - \n",
    "                                             test_6['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_6.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_6.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1d, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_1d = ((test_6['horse_min_vs_standard'] - \n",
    "                                             test_6['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_6.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_6.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_1e, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_1e = ((test_6['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_6['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_6.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_6.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_6 = test_6.assign(feature_3 = ((test_6['horse_median_vs_standard_3'] - \n",
    "                                             test_6['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_6.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_6.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3a, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_3a = ((test_6['horse_mean_vs_standard_3'] - \n",
    "                                             test_6['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_6.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_6.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3b, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_3b = ((test_6['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_6['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_6.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_6.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3c, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_3c = ((test_6['horse_max_vs_standard_3'] - \n",
    "                                             test_6['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_6.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_6.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3d, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_3d = ((test_6['horse_min_vs_standard_3'] - \n",
    "                                             test_6['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_6.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_6.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_6.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_3e, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_6 = test_6.assign(feature_3e = ((test_6['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_6['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_6.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_6 = pd.merge(test_6, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_6.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_6.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, temp_5, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_6 = test_6.assign(jock_pct_race_f5 = \n",
    "               ((test_6['jock_pct'] - test_6['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_6.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_6 = pd.merge(test_6, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_6.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_6.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_6 = pd.merge(test_6, temp_6, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_6 = test_6.assign(trainer_pct_race_f6 = \n",
    "               ((test_6['trainer_pct'] - test_6['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_6 = test_6.assign(jock_trainer_combo = (test_6['trainer'] + test_6['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_6.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_6 = pd.merge(test_6, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_6.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_6.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_6 = pd.merge(test_6, temp_7, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_6 = test_6.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_6['jock_trainer_win_pct'] - test_6['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_6.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_6 = pd.merge(test_6, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_6.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_6.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_6 = pd.merge(test_6, temp_8, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_6 = test_6.assign(bar_win_race_f8 = \n",
    "               ((test_6['bar_win_mean'] - test_6['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_6 = test_6.sort_values(by=['indexing'], ascending =True)\n",
    "test_6 = test_6.reset_index()\n",
    "test_6 = test_6.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_6[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_6[['STORMY VIEW']].head()\n",
    "\n",
    "#test_6.loc[(test_6['date'] == '2019-07-07') & (test_6['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_6[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_6['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_6[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_6 = test_6.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_6.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, race_lbw_max, on='indexing_date_race')\n",
    "test_6.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_6 = test_6.sort_values(by=['indexing'], ascending =True)\n",
    "test_6 = test_6.reset_index()\n",
    "test_6 = test_6.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_6 = test_6.assign(race_lbw_pred = ((test_6['lbw_pred'] - test_6['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_6.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_6['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_6['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_6.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_6 = pd.merge(test_6, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_6.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_6 = test_6.assign(race_prob_pred = ((test_6['prob_pred'] / test_6['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_6 = test_6.assign(race_win_div_pred = ((5 / ((test_6['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_6.loc[(test_6['date'] == '2019-07-07') & (test_6['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_6[test_6.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_6 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>3</td>\n",
       "      <td>FIRE AWAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>5</td>\n",
       "      <td>SUPER SIX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.687500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>INVINCIBLE MAN</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>21.625000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>3</td>\n",
       "      <td>GALVARINO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>7</td>\n",
       "      <td>-5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>8</td>\n",
       "      <td>BE BEE</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>9</td>\n",
       "      <td>NIMBLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>7</td>\n",
       "      <td>MOKASTAR</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race      horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "24  2019-03-15     3       FIRE AWAY  0.0           6.625000         12     -5    12.0          1\n",
       "45  2019-03-15     5       SUPER SIX  0.0          20.687500         21     -5    21.0          1\n",
       "102 2019-03-17     1  INVINCIBLE MAN -4.5          21.625000         22     -5     0.5          0\n",
       "121 2019-03-17     3       GALVARINO  0.0           6.125000          7     -5     7.0          1\n",
       "190 2019-03-17     8          BE BEE -3.8          10.312500         16     -5     0.5          0\n",
       "197 2019-03-17     9          NIMBLE  0.0          16.750000         26     -5    26.0          1\n",
       "278 2019-03-22     7        MOKASTAR -2.3          22.333333         24     -5     0.5          0"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_5 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_5.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_surf_dist')\n",
    "train_5.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_5 = train_5.assign(lengths_vs_standard_1 = \n",
    "                           ((train_5['avg_km_hr_2'] - train_5['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_5['lengths_vs_standard_1'].groupby(train_5['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_5 = pd.merge(train_5, temp, on='horse_name')\n",
    "train_5.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_5.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_5.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_5.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_5.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_5.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_5.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_5.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_1 = ((train_5['horse_median_vs_standard'] - train_5['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_1a = ((train_5['horse_mean_vs_standard'] - train_5['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_1b = ((train_5['horse_top_qtr_vs_standard'] - train_5['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_1c = ((train_5['horse_max_vs_standard'] - train_5['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_5 = train_5.assign(feature_1d = ((train_5['horse_min_vs_standard'] - train_5['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_5 = train_5.assign(feature_1e = ((train_5['horse_bot_qtr_vs_standard'] - train_5['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_5.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_5.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_surf_dist')\n",
    "train_5.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_5 = train_5.assign(lengths_vs_standard_3 = (((((train_5['l100m_km_hr_2'])+(train_5['avg_km_hr_2']))/2) \n",
    "                                         - train_5['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_5['lengths_vs_standard_3'].groupby(train_5['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_5 = pd.merge(train_5, temp, on='horse_name')\n",
    "train_5.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_5.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_5.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_5.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_5.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_5.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_5.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_5.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_3 = ((train_5['horse_median_vs_standard_3'] - train_5['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_3a = ((train_5['horse_mean_vs_standard_3'] - train_5['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_3b = ((train_5['horse_top_qtr_vs_standard_3'] - train_5['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_5 = train_5.assign(feature_3c = ((train_5['horse_max_vs_standard_3'] - train_5['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_5 = train_5.assign(feature_3d = ((train_5['horse_min_vs_standard_3'] - train_5['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_5.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, temp, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_5 = train_5.assign(feature_3e = ((train_5['horse_bot_qtr_vs_standard_3'] - train_5['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "train_5 = train_5.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_5[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_5 = pd.merge(train_5, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_5.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, jockey_pct_race, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_5 = train_5.assign(jock_pct_race_f5 = \n",
    "               ((train_5['jock_pct'] - train_5['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_5[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_5 = pd.merge(train_5, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_5.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, trainer_pct_race, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_5 = train_5.assign(trainer_pct_race_f6 = \n",
    "               ((train_5['trainer_pct'] - train_5['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_5 = train_5.assign(jock_trainer_combo = (train_5['trainer'] + train_5['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_5[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_5 = pd.merge(train_5, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_5.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_5 = train_5.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_5['jock_trainer_win_pct'] - train_5['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_5.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_5 = pd.merge(train_5, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_5.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_5 = pd.merge(train_5, bar_win_max_race, on='indexing_date_race')\n",
    "train_5.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_5 = train_5.assign(bar_win_race_f8 = ((train_5['bar_win_mean'] - train_5['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_5 = train_5.sort_values(by=['indexing'], ascending =True)\n",
    "train_5 = train_5.reset_index()\n",
    "train_5 = train_5.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_5.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_5.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_5 = test_5.assign(feature_1 = ((test_5['horse_median_vs_standard'] - \n",
    "                                             test_5['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_5.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_5.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1a, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_1a = ((test_5['horse_mean_vs_standard'] - \n",
    "                                             test_5['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_5.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_5.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1b, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_1b = ((test_5['horse_top_qtr_vs_standard'] - \n",
    "                                             test_5['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_5.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_5.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1c, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_1c = ((test_5['horse_max_vs_standard'] - \n",
    "                                             test_5['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_5.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_5.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1d, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_1d = ((test_5['horse_min_vs_standard'] - \n",
    "                                             test_5['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_5.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_5.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_1e, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_1e = ((test_5['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_5['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_5.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_5.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_5 = test_5.assign(feature_3 = ((test_5['horse_median_vs_standard_3'] - \n",
    "                                             test_5['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_5.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_5.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3a, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_3a = ((test_5['horse_mean_vs_standard_3'] - \n",
    "                                             test_5['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_5.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_5.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3b, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_3b = ((test_5['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_5['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_5.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_5.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3c, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_3c = ((test_5['horse_max_vs_standard_3'] - \n",
    "                                             test_5['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_5.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_5.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3d, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_3d = ((test_5['horse_min_vs_standard_3'] - \n",
    "                                             test_5['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_5.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_5.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_5.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_3e, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_5 = test_5.assign(feature_3e = ((test_5['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_5['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_5.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_5 = pd.merge(test_5, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_5.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_5.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, temp_5, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_5 = test_5.assign(jock_pct_race_f5 = \n",
    "               ((test_5['jock_pct'] - test_5['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_5.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_5 = pd.merge(test_5, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_5.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_5.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_5 = pd.merge(test_5, temp_6, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_5 = test_5.assign(trainer_pct_race_f6 = \n",
    "               ((test_5['trainer_pct'] - test_5['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_5 = test_5.assign(jock_trainer_combo = (test_5['trainer'] + test_5['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_5.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_5 = pd.merge(test_5, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_5.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_5.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_5 = pd.merge(test_5, temp_7, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_5 = test_5.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_5['jock_trainer_win_pct'] - test_5['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_5.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_5 = pd.merge(test_5, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_5.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_5.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_5 = pd.merge(test_5, temp_8, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_5 = test_5.assign(bar_win_race_f8 = \n",
    "               ((test_5['bar_win_mean'] - test_5['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_5 = test_5.sort_values(by=['indexing'], ascending =True)\n",
    "test_5 = test_5.reset_index()\n",
    "test_5 = test_5.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_5[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_5[['STORMY VIEW']].head()\n",
    "\n",
    "#test_5.loc[(test_5['date'] == '2019-07-07') & (test_5['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_5[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_5['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_5[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_5 = test_5.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_5.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, race_lbw_max, on='indexing_date_race')\n",
    "test_5.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_5 = test_5.sort_values(by=['indexing'], ascending =True)\n",
    "test_5 = test_5.reset_index()\n",
    "test_5 = test_5.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_5 = test_5.assign(race_lbw_pred = ((test_5['lbw_pred'] - test_5['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_5.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_5['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_5['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_5.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_5 = pd.merge(test_5, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_5.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_5 = test_5.assign(race_prob_pred = ((test_5['prob_pred'] / test_5['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_5 = test_5.assign(race_win_div_pred = ((5 / ((test_5['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_5.loc[(test_5['date'] == '2019-07-07') & (test_5['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_5[test_5.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_5 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>GALVARINO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6875</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>SALVADOR</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>13.0625</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>7</td>\n",
       "      <td>GLASGOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.1875</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>3</td>\n",
       "      <td>NORTHERN SUN</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>6</td>\n",
       "      <td>KEEP WINNING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.3750</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>7</td>\n",
       "      <td>ELITE POWER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>7</td>\n",
       "      <td>MOKASTAR</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23.2000</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>8</td>\n",
       "      <td>IRVING LIPSCHITZ</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>8.3125</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>7</td>\n",
       "      <td>QUARTER BACK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6250</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>2</td>\n",
       "      <td>VITTORIA PERFETTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6875</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>2</td>\n",
       "      <td>SUPER WIN</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>20.6875</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>6</td>\n",
       "      <td>CRACKING TOTTIE</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.2500</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>7</td>\n",
       "      <td>MACH</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>8</td>\n",
       "      <td>DEBT COLLECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8125</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race         horse_name   lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "14  2019-03-01     2          GALVARINO   0.0             5.6875         15     -5    15.0          1\n",
       "27  2019-03-01     3           SALVADOR  -0.8            13.0625         15     -5     0.5          0\n",
       "75  2019-03-01     7            GLASGOW   0.0            20.1875         27     -5    27.0          1\n",
       "137 2019-03-03     3       NORTHERN SUN -14.0            14.5000         25     -5     0.5          0\n",
       "165 2019-03-03     6       KEEP WINNING   0.0            24.3750         27     -5    27.0          1\n",
       "176 2019-03-03     7        ELITE POWER   0.0            14.5000         15     -5    15.0          1\n",
       "177 2019-03-03     7           MOKASTAR  -1.0            23.2000         24     -5     0.5          0\n",
       "193 2019-03-03     8   IRVING LIPSCHITZ  -3.9             8.3125         17     -5     0.5          0\n",
       "281 2019-03-08     7       QUARTER BACK   0.0             9.6250         17     -5    17.0          1\n",
       "316 2019-03-10     2  VITTORIA PERFETTA   0.0            20.6875         26     -5    26.0          1\n",
       "321 2019-03-10     2          SUPER WIN  -3.7            20.6875         26     -5     0.5          0\n",
       "367 2019-03-10     6    CRACKING TOTTIE  -3.2            18.2500         25     -5     0.5          0\n",
       "379 2019-03-10     7               MACH  -6.4            14.2500         20     -5     0.5          0\n",
       "386 2019-03-10     8     DEBT COLLECTOR   0.0            10.8125         22     -5    22.0          1"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_4 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_4.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_surf_dist')\n",
    "train_4.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_4 = train_4.assign(lengths_vs_standard_1 = \n",
    "                           ((train_4['avg_km_hr_2'] - train_4['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_4['lengths_vs_standard_1'].groupby(train_4['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_4 = pd.merge(train_4, temp, on='horse_name')\n",
    "train_4.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_4.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_4.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_4.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_4.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_4.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_4.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_4.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_1 = ((train_4['horse_median_vs_standard'] - train_4['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_1a = ((train_4['horse_mean_vs_standard'] - train_4['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_1b = ((train_4['horse_top_qtr_vs_standard'] - train_4['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_1c = ((train_4['horse_max_vs_standard'] - train_4['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_4 = train_4.assign(feature_1d = ((train_4['horse_min_vs_standard'] - train_4['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_4 = train_4.assign(feature_1e = ((train_4['horse_bot_qtr_vs_standard'] - train_4['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_4.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_4.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_surf_dist')\n",
    "train_4.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_4 = train_4.assign(lengths_vs_standard_3 = (((((train_4['l100m_km_hr_2'])+(train_4['avg_km_hr_2']))/2) \n",
    "                                         - train_4['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_4['lengths_vs_standard_3'].groupby(train_4['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_4 = pd.merge(train_4, temp, on='horse_name')\n",
    "train_4.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_4.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_4.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_4.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_4.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_4.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_4.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_4.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_3 = ((train_4['horse_median_vs_standard_3'] - train_4['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_3a = ((train_4['horse_mean_vs_standard_3'] - train_4['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_3b = ((train_4['horse_top_qtr_vs_standard_3'] - train_4['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_4 = train_4.assign(feature_3c = ((train_4['horse_max_vs_standard_3'] - train_4['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_4 = train_4.assign(feature_3d = ((train_4['horse_min_vs_standard_3'] - train_4['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_4.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, temp, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_4 = train_4.assign(feature_3e = ((train_4['horse_bot_qtr_vs_standard_3'] - train_4['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "train_4 = train_4.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_4[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_4 = pd.merge(train_4, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_4.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, jockey_pct_race, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_4 = train_4.assign(jock_pct_race_f5 = \n",
    "               ((train_4['jock_pct'] - train_4['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_4[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_4 = pd.merge(train_4, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_4.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, trainer_pct_race, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_4 = train_4.assign(trainer_pct_race_f6 = \n",
    "               ((train_4['trainer_pct'] - train_4['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_4 = train_4.assign(jock_trainer_combo = (train_4['trainer'] + train_4['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_4[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_4 = pd.merge(train_4, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_4.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_4 = train_4.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_4['jock_trainer_win_pct'] - train_4['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_4.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_4 = pd.merge(train_4, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_4.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_4 = pd.merge(train_4, bar_win_max_race, on='indexing_date_race')\n",
    "train_4.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_4 = train_4.assign(bar_win_race_f8 = ((train_4['bar_win_mean'] - train_4['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_4 = train_4.sort_values(by=['indexing'], ascending =True)\n",
    "train_4 = train_4.reset_index()\n",
    "train_4 = train_4.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_4.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_4.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_4 = test_4.assign(feature_1 = ((test_4['horse_median_vs_standard'] - \n",
    "                                             test_4['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_4.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_4.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1a, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_1a = ((test_4['horse_mean_vs_standard'] - \n",
    "                                             test_4['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_4.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_4.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1b, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_1b = ((test_4['horse_top_qtr_vs_standard'] - \n",
    "                                             test_4['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_4.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_4.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1c, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_1c = ((test_4['horse_max_vs_standard'] - \n",
    "                                             test_4['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_4.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_4.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1d, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_1d = ((test_4['horse_min_vs_standard'] - \n",
    "                                             test_4['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_4.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_4.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_1e, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_1e = ((test_4['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_4['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_4.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_4.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_4 = test_4.assign(feature_3 = ((test_4['horse_median_vs_standard_3'] - \n",
    "                                             test_4['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_4.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_4.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3a, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_3a = ((test_4['horse_mean_vs_standard_3'] - \n",
    "                                             test_4['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_4.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_4.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3b, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_3b = ((test_4['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_4['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_4.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_4.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3c, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_3c = ((test_4['horse_max_vs_standard_3'] - \n",
    "                                             test_4['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_4.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_4.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3d, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_3d = ((test_4['horse_min_vs_standard_3'] - \n",
    "                                             test_4['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_4.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_4.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_4.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_3e, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_4 = test_4.assign(feature_3e = ((test_4['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_4['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_4.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_4 = pd.merge(test_4, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_4.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_4.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, temp_5, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_4 = test_4.assign(jock_pct_race_f5 = \n",
    "               ((test_4['jock_pct'] - test_4['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_4.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_4 = pd.merge(test_4, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_4.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_4.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_4 = pd.merge(test_4, temp_6, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_4 = test_4.assign(trainer_pct_race_f6 = \n",
    "               ((test_4['trainer_pct'] - test_4['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_4 = test_4.assign(jock_trainer_combo = (test_4['trainer'] + test_4['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_4.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_4 = pd.merge(test_4, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_4.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_4.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_4 = pd.merge(test_4, temp_7, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_4 = test_4.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_4['jock_trainer_win_pct'] - test_4['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_4.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_4 = pd.merge(test_4, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_4.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_4.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_4 = pd.merge(test_4, temp_8, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_4 = test_4.assign(bar_win_race_f8 = \n",
    "               ((test_4['bar_win_mean'] - test_4['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_4 = test_4.sort_values(by=['indexing'], ascending =True)\n",
    "test_4 = test_4.reset_index()\n",
    "test_4 = test_4.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_4[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_4[['STORMY VIEW']].head()\n",
    "\n",
    "#test_4.loc[(test_4['date'] == '2019-07-07') & (test_4['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_4[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_4['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_4[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_4 = test_4.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_4.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, race_lbw_max, on='indexing_date_race')\n",
    "test_4.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_4 = test_4.sort_values(by=['indexing'], ascending =True)\n",
    "test_4 = test_4.reset_index()\n",
    "test_4 = test_4.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_4 = test_4.assign(race_lbw_pred = ((test_4['lbw_pred'] - test_4['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_4.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_4['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_4['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_4.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_4 = pd.merge(test_4, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_4.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_4 = test_4.assign(race_prob_pred = ((test_4['prob_pred'] / test_4['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_4 = test_4.assign(race_win_div_pred = ((5 / ((test_4['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_4.loc[(test_4['date'] == '2019-07-07') & (test_4['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_4[test_4.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_4 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>1</td>\n",
       "      <td>RUN THE DAY</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>7.5625</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>2</td>\n",
       "      <td>TOOSBIES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8750</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>ELENA OF AVALOR</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>6</td>\n",
       "      <td>NADEEM SAPPHIRE</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>18.2500</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>BE BEE</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>9.3750</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>4</td>\n",
       "      <td>RUN THE DAY</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>7.5625</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race       horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "3   2019-02-15     1      RUN THE DAY -1.6             7.5625         20     -5     0.5          0\n",
       "107 2019-02-17     2         TOOSBIES  0.0            13.8750         17     -5    17.0          1\n",
       "131 2019-02-17     4  ELENA OF AVALOR -0.5            11.0000         15     -5     0.5          0\n",
       "152 2019-02-17     6  NADEEM SAPPHIRE -2.1            18.2500         25     -5     0.5          0\n",
       "161 2019-02-17     7           BE BEE -0.5             9.3750         18     -5     0.5          0\n",
       "243 2019-02-22     4      RUN THE DAY -9.5             7.5625         20     -5     0.5          0"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_3 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_3.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_surf_dist')\n",
    "train_3.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_3 = train_3.assign(lengths_vs_standard_1 = \n",
    "                           ((train_3['avg_km_hr_2'] - train_3['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_3['lengths_vs_standard_1'].groupby(train_3['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_3 = pd.merge(train_3, temp, on='horse_name')\n",
    "train_3.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_3.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_3.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_3.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_3.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_3.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_3.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_3.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_1 = ((train_3['horse_median_vs_standard'] - train_3['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_1a = ((train_3['horse_mean_vs_standard'] - train_3['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_1b = ((train_3['horse_top_qtr_vs_standard'] - train_3['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_1c = ((train_3['horse_max_vs_standard'] - train_3['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_3 = train_3.assign(feature_1d = ((train_3['horse_min_vs_standard'] - train_3['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_3 = train_3.assign(feature_1e = ((train_3['horse_bot_qtr_vs_standard'] - train_3['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_3.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_3.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_surf_dist')\n",
    "train_3.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_3 = train_3.assign(lengths_vs_standard_3 = (((((train_3['l100m_km_hr_2'])+(train_3['avg_km_hr_2']))/2) \n",
    "                                         - train_3['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_3['lengths_vs_standard_3'].groupby(train_3['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_3 = pd.merge(train_3, temp, on='horse_name')\n",
    "train_3.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_3.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_3.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_3.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_3.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_3.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_3.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_3.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_3 = ((train_3['horse_median_vs_standard_3'] - train_3['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_3a = ((train_3['horse_mean_vs_standard_3'] - train_3['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_3b = ((train_3['horse_top_qtr_vs_standard_3'] - train_3['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_3 = train_3.assign(feature_3c = ((train_3['horse_max_vs_standard_3'] - train_3['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_3 = train_3.assign(feature_3d = ((train_3['horse_min_vs_standard_3'] - train_3['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_3.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, temp, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_3 = train_3.assign(feature_3e = ((train_3['horse_bot_qtr_vs_standard_3'] - train_3['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "train_3 = train_3.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_3[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_3 = pd.merge(train_3, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_3.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, jockey_pct_race, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_3 = train_3.assign(jock_pct_race_f5 = \n",
    "               ((train_3['jock_pct'] - train_3['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_3[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_3 = pd.merge(train_3, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_3.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, trainer_pct_race, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_3 = train_3.assign(trainer_pct_race_f6 = \n",
    "               ((train_3['trainer_pct'] - train_3['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_3 = train_3.assign(jock_trainer_combo = (train_3['trainer'] + train_3['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_3[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_3 = pd.merge(train_3, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_3.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_3 = train_3.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_3['jock_trainer_win_pct'] - train_3['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_3.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_3 = pd.merge(train_3, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_3.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_3 = pd.merge(train_3, bar_win_max_race, on='indexing_date_race')\n",
    "train_3.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_3 = train_3.assign(bar_win_race_f8 = ((train_3['bar_win_mean'] - train_3['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_3 = train_3.sort_values(by=['indexing'], ascending =True)\n",
    "train_3 = train_3.reset_index()\n",
    "train_3 = train_3.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_3.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_3.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_3 = test_3.assign(feature_1 = ((test_3['horse_median_vs_standard'] - \n",
    "                                             test_3['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_3.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_3.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1a, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_1a = ((test_3['horse_mean_vs_standard'] - \n",
    "                                             test_3['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_3.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_3.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1b, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_1b = ((test_3['horse_top_qtr_vs_standard'] - \n",
    "                                             test_3['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_3.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_3.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1c, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_1c = ((test_3['horse_max_vs_standard'] - \n",
    "                                             test_3['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_3.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_3.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1d, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_1d = ((test_3['horse_min_vs_standard'] - \n",
    "                                             test_3['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_3.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_3.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_1e, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_1e = ((test_3['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_3['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_3.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_3.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_3 = test_3.assign(feature_3 = ((test_3['horse_median_vs_standard_3'] - \n",
    "                                             test_3['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_3.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_3.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3a, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_3a = ((test_3['horse_mean_vs_standard_3'] - \n",
    "                                             test_3['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_3.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_3.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3b, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_3b = ((test_3['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_3['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_3.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_3.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3c, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_3c = ((test_3['horse_max_vs_standard_3'] - \n",
    "                                             test_3['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_3.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_3.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3d, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_3d = ((test_3['horse_min_vs_standard_3'] - \n",
    "                                             test_3['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_3.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_3.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_3.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_3e, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_3 = test_3.assign(feature_3e = ((test_3['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_3['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_3.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_3 = pd.merge(test_3, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_3.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_3.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, temp_5, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_3 = test_3.assign(jock_pct_race_f5 = \n",
    "               ((test_3['jock_pct'] - test_3['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_3.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_3 = pd.merge(test_3, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_3.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_3.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_3 = pd.merge(test_3, temp_6, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_3 = test_3.assign(trainer_pct_race_f6 = \n",
    "               ((test_3['trainer_pct'] - test_3['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_3 = test_3.assign(jock_trainer_combo = (test_3['trainer'] + test_3['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_3.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_3 = pd.merge(test_3, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_3.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_3.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_3 = pd.merge(test_3, temp_7, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_3 = test_3.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_3['jock_trainer_win_pct'] - test_3['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_3.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_3 = pd.merge(test_3, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_3.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_3.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_3 = pd.merge(test_3, temp_8, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_3 = test_3.assign(bar_win_race_f8 = \n",
    "               ((test_3['bar_win_mean'] - test_3['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_3 = test_3.sort_values(by=['indexing'], ascending =True)\n",
    "test_3 = test_3.reset_index()\n",
    "test_3 = test_3.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_3[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_3[['STORMY VIEW']].head()\n",
    "\n",
    "#test_3.loc[(test_3['date'] == '2019-07-07') & (test_3['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_3[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_3['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_3[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_3 = test_3.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_3.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, race_lbw_max, on='indexing_date_race')\n",
    "test_3.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_3 = test_3.sort_values(by=['indexing'], ascending =True)\n",
    "test_3 = test_3.reset_index()\n",
    "test_3 = test_3.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_3 = test_3.assign(race_lbw_pred = ((test_3['lbw_pred'] - test_3['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_3.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_3['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_3['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_3.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_3 = pd.merge(test_3, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_3.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_3 = test_3.assign(race_prob_pred = ((test_3['prob_pred'] / test_3['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_3 = test_3.assign(race_win_div_pred = ((5 / ((test_3['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_3.loc[(test_3['date'] == '2019-07-07') & (test_3['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_3[test_3.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True)  \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_3 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>4</td>\n",
       "      <td>SALAMENCE</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>17.187500</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>2</td>\n",
       "      <td>COLOUR PAINT</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>14.812500</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>4</td>\n",
       "      <td>SACRED CROIX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>6</td>\n",
       "      <td>EASTIGER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>8</td>\n",
       "      <td>IMPERIAL FALLS</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>20.538462</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>2</td>\n",
       "      <td>JUPITER DRAGON</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>3</td>\n",
       "      <td>IRVING LIPSCHITZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>4</td>\n",
       "      <td>ACCUMULATION</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>11.187500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>6</td>\n",
       "      <td>QUARTER BACK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>6</td>\n",
       "      <td>EYE GUY</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>20.363636</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>7</td>\n",
       "      <td>BEBOP</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>8</td>\n",
       "      <td>MISTER YEOH</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>4</td>\n",
       "      <td>SACRED DON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.187500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race        horse_name   lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "47  2019-02-01     4         SALAMENCE  -8.7          17.187500         25     -5     0.5          0\n",
       "117 2019-02-03     2      COLOUR PAINT  -5.2          14.812500         25     -5     0.5          0\n",
       "134 2019-02-03     4      SACRED CROIX   0.0           6.625000         19     -5    19.0          1\n",
       "156 2019-02-03     6          EASTIGER   0.0           8.312500         17     -5    17.0          1\n",
       "188 2019-02-03     8    IMPERIAL FALLS -13.7          20.538462         22     -5     0.5          0\n",
       "215 2019-02-06     2    JUPITER DRAGON  -2.7          16.062500         19     -5     0.5          0\n",
       "225 2019-02-06     3  IRVING LIPSCHITZ   0.0           7.125000         21     -5    21.0          1\n",
       "235 2019-02-06     4      ACCUMULATION  -6.5          11.187500         19     -5     0.5          0\n",
       "254 2019-02-06     6      QUARTER BACK   0.0          14.000000         22     -5    22.0          1\n",
       "261 2019-02-06     6           EYE GUY  -5.1          20.363636         21     -5     0.5          0\n",
       "269 2019-02-06     7             BEBOP  -0.5          16.062500         21     -5     0.5          0\n",
       "282 2019-02-06     8       MISTER YEOH  -1.7          17.687500         21     -5     0.5          0\n",
       "342 2019-02-08     4        SACRED DON   0.0          14.187500         15     -5    15.0          1"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_2 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_2.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_surf_dist')\n",
    "train_2.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_2 = train_2.assign(lengths_vs_standard_1 = \n",
    "                           ((train_2['avg_km_hr_2'] - train_2['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_2['lengths_vs_standard_1'].groupby(train_2['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_2 = pd.merge(train_2, temp, on='horse_name')\n",
    "train_2.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_2.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_2.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_2.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_2.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_2.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_2.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_2.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_1 = ((train_2['horse_median_vs_standard'] - train_2['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_1a = ((train_2['horse_mean_vs_standard'] - train_2['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_1b = ((train_2['horse_top_qtr_vs_standard'] - train_2['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_1c = ((train_2['horse_max_vs_standard'] - train_2['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_2 = train_2.assign(feature_1d = ((train_2['horse_min_vs_standard'] - train_2['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_2 = train_2.assign(feature_1e = ((train_2['horse_bot_qtr_vs_standard'] - train_2['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_2.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_2.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_surf_dist')\n",
    "train_2.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_2 = train_2.assign(lengths_vs_standard_3 = (((((train_2['l100m_km_hr_2'])+(train_2['avg_km_hr_2']))/2) \n",
    "                                         - train_2['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_2['lengths_vs_standard_3'].groupby(train_2['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_2 = pd.merge(train_2, temp, on='horse_name')\n",
    "train_2.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_2.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_2.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_2.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_2.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_2.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_2.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_2.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_3 = ((train_2['horse_median_vs_standard_3'] - train_2['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_3a = ((train_2['horse_mean_vs_standard_3'] - train_2['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_3b = ((train_2['horse_top_qtr_vs_standard_3'] - train_2['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_2 = train_2.assign(feature_3c = ((train_2['horse_max_vs_standard_3'] - train_2['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_2 = train_2.assign(feature_3d = ((train_2['horse_min_vs_standard_3'] - train_2['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_2.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, temp, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_2 = train_2.assign(feature_3e = ((train_2['horse_bot_qtr_vs_standard_3'] - train_2['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "train_2 = train_2.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_2[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_2 = pd.merge(train_2, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_2.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, jockey_pct_race, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_2 = train_2.assign(jock_pct_race_f5 = \n",
    "               ((train_2['jock_pct'] - train_2['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_2[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_2 = pd.merge(train_2, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_2.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, trainer_pct_race, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_2 = train_2.assign(trainer_pct_race_f6 = \n",
    "               ((train_2['trainer_pct'] - train_2['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_2 = train_2.assign(jock_trainer_combo = (train_2['trainer'] + train_2['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_2[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_2 = pd.merge(train_2, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_2.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_2 = train_2.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_2['jock_trainer_win_pct'] - train_2['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_2.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_2 = pd.merge(train_2, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_2.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_2 = pd.merge(train_2, bar_win_max_race, on='indexing_date_race')\n",
    "train_2.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_2 = train_2.assign(bar_win_race_f8 = ((train_2['bar_win_mean'] - train_2['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_2 = train_2.sort_values(by=['indexing'], ascending =True)\n",
    "train_2 = train_2.reset_index()\n",
    "train_2 = train_2.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_2.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_2.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_2 = test_2.assign(feature_1 = ((test_2['horse_median_vs_standard'] - \n",
    "                                             test_2['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_2.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_2.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1a, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_1a = ((test_2['horse_mean_vs_standard'] - \n",
    "                                             test_2['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_2.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_2.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1b, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_1b = ((test_2['horse_top_qtr_vs_standard'] - \n",
    "                                             test_2['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_2.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_2.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1c, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_1c = ((test_2['horse_max_vs_standard'] - \n",
    "                                             test_2['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_2.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_2.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1d, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_1d = ((test_2['horse_min_vs_standard'] - \n",
    "                                             test_2['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_2.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_2.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_1e, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_1e = ((test_2['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_2['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_2.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_2.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_2 = test_2.assign(feature_3 = ((test_2['horse_median_vs_standard_3'] - \n",
    "                                             test_2['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_2.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_2.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3a, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_3a = ((test_2['horse_mean_vs_standard_3'] - \n",
    "                                             test_2['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_2.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_2.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3b, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_3b = ((test_2['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_2['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_2.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_2.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3c, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_3c = ((test_2['horse_max_vs_standard_3'] - \n",
    "                                             test_2['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_2.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_2.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3d, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_3d = ((test_2['horse_min_vs_standard_3'] - \n",
    "                                             test_2['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_2.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_2.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_2.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_3e, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_2 = test_2.assign(feature_3e = ((test_2['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_2['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_2.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_2 = pd.merge(test_2, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_2.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_2.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, temp_5, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_2 = test_2.assign(jock_pct_race_f5 = \n",
    "               ((test_2['jock_pct'] - test_2['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_2.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_2 = pd.merge(test_2, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_2.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_2.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_2 = pd.merge(test_2, temp_6, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_2 = test_2.assign(trainer_pct_race_f6 = \n",
    "               ((test_2['trainer_pct'] - test_2['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_2 = test_2.assign(jock_trainer_combo = (test_2['trainer'] + test_2['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_2.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_2 = pd.merge(test_2, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_2.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_2.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_2 = pd.merge(test_2, temp_7, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_2 = test_2.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_2['jock_trainer_win_pct'] - test_2['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_2.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_2 = pd.merge(test_2, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_2.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_2.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_2 = pd.merge(test_2, temp_8, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_2 = test_2.assign(bar_win_race_f8 = \n",
    "               ((test_2['bar_win_mean'] - test_2['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_2 = test_2.sort_values(by=['indexing'], ascending =True)\n",
    "test_2 = test_2.reset_index()\n",
    "test_2 = test_2.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_2[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_2[['STORMY VIEW']].head()\n",
    "\n",
    "#test_2.loc[(test_2['date'] == '2019-07-07') & (test_2['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_2[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_2['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_2[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_2 = test_2.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_2.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, race_lbw_max, on='indexing_date_race')\n",
    "test_2.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_2 = test_2.sort_values(by=['indexing'], ascending =True)\n",
    "test_2 = test_2.reset_index()\n",
    "test_2 = test_2.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_2 = test_2.assign(race_lbw_pred = ((test_2['lbw_pred'] - test_2['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_2.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_2['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_2['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_2.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_2 = pd.merge(test_2, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_2.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_2 = test_2.assign(race_prob_pred = ((test_2['prob_pred'] / test_2['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_2 = test_2.assign(race_win_div_pred = ((5 / ((test_2['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_2.loc[(test_2['date'] == '2019-07-07') & (test_2['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_2[test_2.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "accumulated_profit_loss_2 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>EVERYBODY HAPPY</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>10.687500</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>3</td>\n",
       "      <td>NO FUN NO GAIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>4</td>\n",
       "      <td>SACRED DON</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>7</td>\n",
       "      <td>BE BEE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>8</td>\n",
       "      <td>MACH</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>6</td>\n",
       "      <td>MAJESTIC EMPRESS</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>9</td>\n",
       "      <td>NIMBLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.437500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>4</td>\n",
       "      <td>ELENA OF AVALOR</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>19.142857</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>8</td>\n",
       "      <td>LUCKY HADA</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race        horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "5   2019-01-18     1   EVERYBODY HAPPY -2.3          10.687500         13     -5     0.5          0\n",
       "23  2019-01-18     3    NO FUN NO GAIN  0.0          14.562500         17     -5    17.0          1\n",
       "35  2019-01-18     4        SACRED DON -1.0          13.375000         16     -5     0.5          0\n",
       "68  2019-01-18     7            BE BEE  0.0           9.687500         16     -5    16.0          1\n",
       "85  2019-01-18     8              MACH -4.0          14.250000         25     -5     0.5          0\n",
       "141 2019-01-20     6  MAJESTIC EMPRESS -1.0          19.750000         27     -5     0.5          0\n",
       "168 2019-01-20     9            NIMBLE  0.0          13.437500         15     -5    15.0          1\n",
       "218 2019-01-25     4   ELENA OF AVALOR -2.3          19.142857         26     -5     0.5          0\n",
       "259 2019-01-25     8        LUCKY HADA -1.5          22.666667         25     -5     0.5          0"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_1 Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STANDARD SPEED:\n",
    "# Create 'standard_speed' (avg_speed on surface & distance) merge back to df:\n",
    "temp = train_1.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['mean']) \n",
    "\n",
    "# merge standard_speed_1 back into df & rename(columns={'median': 'standard_speed_1'}, inplace=True)\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_surf_dist')\n",
    "train_1.rename(columns={'mean': 'standard_speed_1'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON AVG_KM_HR:\n",
    "# Horse speed vs standard in lengths \n",
    "train_1 = train_1.assign(lengths_vs_standard_1 = \n",
    "                           ((train_1['avg_km_hr_2'] - train_1['standard_speed_1'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_1['lengths_vs_standard_1'].groupby(train_1['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_1 = pd.merge(train_1, temp, on='horse_name')\n",
    "train_1.rename(columns={'50%': 'horse_median_vs_standard'}, inplace=True)   #f1\n",
    "\n",
    "# used for other engineered features:\n",
    "train_1.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)    #f1a\n",
    "train_1.rename(columns={'75%': 'horse_top_qtr_vs_standard'}, inplace=True)  #f1b\n",
    "train_1.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)      #f1c\n",
    "train_1.rename(columns={'min': 'horse_min_vs_standard'}, inplace=True)      #f1d\n",
    "train_1.rename(columns={'25%': 'horse_bot_qtr_vs_standard'}, inplace=True)  #f1e\n",
    "\n",
    "train_1.rename(columns={'std': 'horse_stdev'}, inplace=True)                #f1f\n",
    "train_1.rename(columns={'count': 'horse_race_count'}, inplace=True)         #f1g\n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_1'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_1 = ((train_1['horse_median_vs_standard'] - train_1['temp_1'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_1', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1A\n",
    "#Engineered Feature 1a: Mean Speed\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_1a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_1a = ((train_1['horse_mean_vs_standard'] - train_1['temp_1a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_1a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_1b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_1b = ((train_1['horse_top_qtr_vs_standard'] - train_1['temp_1b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_1b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 1C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_1c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_1c = ((train_1['horse_max_vs_standard'] - train_1['temp_1c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_1c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_1d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_1 = train_1.assign(feature_1d = ((train_1['horse_min_vs_standard'] - train_1['temp_1d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_1d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 1E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_1e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_1 = train_1.assign(feature_1e = ((train_1['horse_bot_qtr_vs_standard'] - train_1['temp_1e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_1e', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#STANDARD SPEED_3:\n",
    "# Create 'standard_speed' (avg_speed & l100m) on surface & distance) merge back to df:\n",
    "temp = ((train_1.groupby(['indexing_surf_dist']).avg_km_hr_2.agg(['median'])) \n",
    "        + (train_1.groupby(['indexing_surf_dist']).l100m_km_hr_2.agg(['median'])))/2\n",
    "\n",
    "# merge standard_speed_2 back into df & rename(columns={'median': 'standard_speed_2'}, inplace=True)\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_surf_dist')\n",
    "train_1.rename(columns={'median': 'standard_speed_3'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DESCRIBE TABLE ON F1 & F2:\n",
    "# Horse speed & l100m vs standard in lengths \n",
    "train_1 = train_1.assign(lengths_vs_standard_3 = (((((train_1['l100m_km_hr_2'])+(train_1['avg_km_hr_2']))/2) \n",
    "                                         - train_1['standard_speed_3'] ) * 7)) # 7 lengths/kmph\n",
    "\n",
    "# Groupby Horse on stats:\n",
    "temp = train_1['lengths_vs_standard_3'].groupby(train_1['horse_name']).describe(include=all)\n",
    "\n",
    "# merge desc back into df groupby horse (this is the horses detailed speed fig)\n",
    "train_1 = pd.merge(train_1, temp, on='horse_name')\n",
    "train_1.rename(columns={'50%': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "# used for other engineered features:\n",
    "train_1.rename(columns={'mean': 'horse_mean_vs_standard_3'}, inplace=True)    #f2a\n",
    "train_1.rename(columns={'75%': 'horse_top_qtr_vs_standard_3'}, inplace=True)  #f2b\n",
    "train_1.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)      #f2c\n",
    "train_1.rename(columns={'min': 'horse_min_vs_standard_3'}, inplace=True)      #f2d\n",
    "train_1.rename(columns={'25%': 'horse_bot_qtr_vs_standard_3'}, inplace=True)  #f2e\n",
    "\n",
    "train_1.rename(columns={'std': 'horse_stdev_3'}, inplace=True)                #f2f\n",
    "train_1.rename(columns={'count': 'horse_race_count_3'}, inplace=True)         #f2g\n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3:\n",
    "# Median speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_3'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_3 = ((train_1['horse_median_vs_standard_3'] - train_1['temp_3'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_3', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3A:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_3a'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_3a = ((train_1['horse_mean_vs_standard_3'] - train_1['temp_3a'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_3a', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3B:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_3b'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_3b = ((train_1['horse_top_qtr_vs_standard_3'] - train_1['temp_3b'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_3b', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3C:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_3c'}, inplace=True)\n",
    "\n",
    "# new column in df 'f1_horse_lengths_vs_max_in_race' calc\n",
    "train_1 = train_1.assign(feature_3c = ((train_1['horse_max_vs_standard_3'] - train_1['temp_3c'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_3c', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3D:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_3d'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "train_1 = train_1.assign(feature_3d = ((train_1['horse_min_vs_standard_3'] - train_1['temp_3d'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_3d', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 3E:\n",
    "# Mean speed then Groupby date & surf, and calc max for each race as save in temp df:\n",
    "temp = train_1.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, temp, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'temp_3e'}, inplace=True)\n",
    "\n",
    "# new column in df \n",
    "train_1 = train_1.assign(feature_3e = ((train_1['horse_bot_qtr_vs_standard_3'] - train_1['temp_3e'] ) )) \n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "train_1 = train_1.drop('temp_3e', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 5:\n",
    "# 'jock_pct':\n",
    "jock_win = train_1[['jockey', 'win_count', 'total_count']].groupby('jockey').agg('sum')\n",
    "jock_win = jock_win.assign(jock_pct = (jock_win['win_count'] / jock_win['total_count']) * 100)\n",
    "jock_win = jock_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_1 = pd.merge(train_1, jock_win, on='jockey')\n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "jockey_pct_race = train_1.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, jockey_pct_race, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "train_1 = train_1.assign(jock_pct_race_f5 = \n",
    "               ((train_1['jock_pct'] - train_1['max_jock_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 6:\n",
    "# 'trainer_pct':\n",
    "trainer_win = train_1[['trainer', 'win_count', 'total_count']].groupby('trainer').agg('sum')\n",
    "trainer_win = trainer_win.assign(trainer_pct = (trainer_win['win_count'] / trainer_win['total_count']) * 100)\n",
    "trainer_win = trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_1 = pd.merge(train_1, trainer_win, on='trainer')\n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max trainer % (to be used in calc of each trainer's race % relative):\n",
    "trainer_pct_race = train_1.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, trainer_pct_race, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f6_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_1 = train_1.assign(trainer_pct_race_f6 = \n",
    "               ((train_1['trainer_pct'] - train_1['max_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE 7:\n",
    "# 'jock_trainer_pct':\n",
    "train_1 = train_1.assign(jock_trainer_combo = (train_1['trainer'] + train_1['jockey'])  )\n",
    "\n",
    "jock_trainer_win = train_1[['jock_trainer_combo', 'win_count', 'total_count']\n",
    "                           ].groupby('jock_trainer_combo').agg('sum')\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.assign(jock_trainer_win_pct = ((jock_trainer_win['win_count'] \n",
    "                                                                   / jock_trainer_win['total_count'])) /2 * 100)\n",
    "\n",
    "jock_trainer_win = jock_trainer_win.drop(['win_count', 'total_count'], axis=1)\n",
    "train_1 = pd.merge(train_1, jock_trainer_win, on='jock_trainer_combo')\n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max jock_trainer % (to be used in calc of each jock_trainer's race % relative):\n",
    "jock_trainer_pct_race = train_1.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, jock_trainer_pct_race, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f7_jock_trainer_pct_race' calc (sort of expressed as lbw)\n",
    "train_1 = train_1.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((train_1['jock_trainer_win_pct'] - train_1['max_jock_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#FEATURE 8:\n",
    "# barrier bias (for merging back to df):\n",
    "bar_win = train_1.groupby(['indexing_surf_dist_bar']).win_count.agg(['mean']) * 100\n",
    "bar_win.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "train_1 = pd.merge(train_1, bar_win, on='indexing_surf_dist_bar')\n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "\n",
    "# Groupby date & race, then max bar % (to be used in calc of each bar's race % relative):\n",
    "bar_win_max_race = train_1.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "train_1 = pd.merge(train_1, bar_win_max_race, on='indexing_date_race')\n",
    "train_1.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f8 (sort of expressed as lbw)\n",
    "train_1 = train_1.assign(bar_win_race_f8 = ((train_1['bar_win_mean'] - train_1['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "train_1 = train_1.sort_values(by=['indexing'], ascending =True)\n",
    "train_1 = train_1.reset_index()\n",
    "train_1 = train_1.drop('index', axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test_1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1:\n",
    "# Groupby horse_name, then calc max to temp_1\n",
    "temp_1 = train_1.groupby(['horse_name']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1 = test_1.groupby(['indexing_date_race']).horse_median_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_median_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df 'f2_horse_lengths_vs_max_in_race' calc\n",
    "test_1 = test_1.assign(feature_1 = ((test_1['horse_median_vs_standard'] - \n",
    "                                             test_1['max_race_horse_median_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1a:\n",
    "# Groupby horse_name, then calc max to temp_1a\n",
    "temp_1a = train_1.groupby(['horse_name']).horse_mean_vs_standard.agg(['mean'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'mean': 'horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1a = test_1.groupby(['indexing_date_race']).horse_mean_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1a, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_mean_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_1a = ((test_1['horse_mean_vs_standard'] - \n",
    "                                             test_1['max_race_horse_mean_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1b:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1b = train_1.groupby(['horse_name']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1b = test_1.groupby(['indexing_date_race']).horse_top_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1b, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_1b = ((test_1['horse_top_qtr_vs_standard'] - \n",
    "                                             test_1['max_race_horse_top_qtr_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1c:\n",
    "# Groupby horse_name, then calc max to temp_1b\n",
    "temp_1c = train_1.groupby(['horse_name']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1c = test_1.groupby(['indexing_date_race']).horse_max_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1c, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_max_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_1c = ((test_1['horse_max_vs_standard'] - \n",
    "                                             test_1['max_race_horse_max_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1d:\n",
    "# Groupby horse_name, then calc max to temp_1d\n",
    "temp_1d = train_1.groupby(['horse_name']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1d = test_1.groupby(['indexing_date_race']).horse_min_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1d, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_min_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_1d = ((test_1['horse_min_vs_standard'] - \n",
    "                                             test_1['max_race_horse_min_vs_standard'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1e:\n",
    "# Groupby horse_name, then calc max to temp_1e\n",
    "temp_1e = train_1.groupby(['horse_name']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_1e = test_1.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_1e, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_1e = ((test_1['horse_bot_qtr_vs_standard'] - \n",
    "                                             test_1['max_race_horse_bot_qtr_vs_standard'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature 3:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3 = train_1.groupby(['horse_name']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3 = test_1.groupby(['indexing_date_race']).horse_median_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_median_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column \n",
    "test_1 = test_1.assign(feature_3 = ((test_1['horse_median_vs_standard_3'] - \n",
    "                                             test_1['max_race_horse_median_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3a:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3a = train_1.groupby(['horse_name']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3a, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3a = test_1.groupby(['indexing_date_race']).horse_mean_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3a, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_mean_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_3a = ((test_1['horse_mean_vs_standard_3'] - \n",
    "                                             test_1['max_race_horse_mean_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3b:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3b = train_1.groupby(['horse_name']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3b, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3b = test_1.groupby(['indexing_date_race']).horse_top_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3b, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_top_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_3b = ((test_1['horse_top_qtr_vs_standard_3'] - \n",
    "                                             test_1['max_race_horse_top_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature 3c:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3c = train_1.groupby(['horse_name']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3c, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3c = test_1.groupby(['indexing_date_race']).horse_max_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3c, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_max_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_3c = ((test_1['horse_max_vs_standard_3'] - \n",
    "                                             test_1['max_race_horse_max_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3d:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3d = train_1.groupby(['horse_name']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3d, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3d = test_1.groupby(['indexing_date_race']).horse_min_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3d, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_min_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_3d = ((test_1['horse_min_vs_standard_3'] - \n",
    "                                             test_1['max_race_horse_min_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3e:\n",
    "# Groupby horse_name, then calc max \n",
    "temp_3e = train_1.groupby(['horse_name']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge back into df_rc groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3e, on='horse_name', how='left').fillna(-3) # dummy number for now\n",
    "test_1.rename(columns={'max': 'horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# MAX IN RACE OF (HORSE MAX SPEED FIGURE (LENGTHS VS STANDARD))\n",
    "# Groupby date & surf, then calc max for each race as save in temp df_rc:\n",
    "temp_3e = test_1.groupby(['indexing_date_race']).horse_bot_qtr_vs_standard_3.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_3e, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_race_horse_bot_qtr_vs_standard_3'}, inplace=True)\n",
    "\n",
    "\n",
    "# HORSE FIG - RACE MAX \n",
    "# new column in df_rc\n",
    "test_1 = test_1.assign(feature_3e = ((test_1['horse_bot_qtr_vs_standard_3'] - \n",
    "                                             test_1['max_race_horse_bot_qtr_vs_standard_3'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jockey Win %\n",
    "# Groupby horse_name calc median to temp_4\n",
    "temp_5 = train_1.groupby(['jockey']).jock_pct.agg(['mean'])\n",
    "\n",
    "# merge median avg lengths vs standard back into df groupby horse (this is the horses speed fig)\n",
    "test_1 = pd.merge(test_1, temp_5, on='jockey', how='left').fillna(0) # dummy number for now\n",
    "test_1.rename(columns={'mean': 'jock_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, then sum jockey % (to be used in calc of each jockey's race % relative):\n",
    "temp_5 = test_1.groupby(['indexing_date_race']).jock_pct.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, temp_5, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_jock_pct_race'}, inplace=True)\n",
    "\n",
    "# new column in df 'f5_jock_pct_race' calc (sort of expressed as lbw)\n",
    "test_1 = test_1.assign(jock_pct_race_f5 = \n",
    "               ((test_1['jock_pct'] - test_1['max_jock_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Win %\n",
    "# Groupby horse_name calc mean\n",
    "temp_6 = train_1.groupby(['trainer']).trainer_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_1 = pd.merge(test_1, temp_6, on='trainer', how='left').fillna(0) # dummy number for now\n",
    "test_1.rename(columns={'mean': 'trainer_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_6 = test_1.groupby(['indexing_date_race']).trainer_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_1 = pd.merge(test_1, temp_6, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_1 = test_1.assign(trainer_pct_race_f6 = \n",
    "               ((test_1['trainer_pct'] - test_1['max_trainer_pct_race'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer Jockey Combo Win %\n",
    "# new column 'jock_trainer_pct':\n",
    "test_1 = test_1.assign(jock_trainer_combo = (test_1['trainer'] + test_1['jockey']) )\n",
    "\n",
    "# Groupby horse_name calc mean\n",
    "temp_7 = train_1.groupby(['jock_trainer_combo']).jock_trainer_win_pct.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_1 = pd.merge(test_1, temp_7, on='jock_trainer_combo', how='left').fillna(0) # dummy number for now\n",
    "test_1.rename(columns={'mean': 'jock_trainer_win_pct'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_7 = test_1.groupby(['indexing_date_race']).jock_trainer_win_pct.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_1 = pd.merge(test_1, temp_7, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'max_jock_trainer_pct_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_1 = test_1.assign(jock_trainer_win_pct_race_f7 = \n",
    "               ((test_1['jock_trainer_win_pct'] - test_1['max_jock_trainer_pct_race'] ) )) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barrier %\n",
    "# Groupby horse_name calc mean\n",
    "temp_8 = train_1.groupby(['indexing_surf_dist_bar']).bar_win_mean.agg(['mean'])\n",
    "\n",
    "# merge \n",
    "test_1 = pd.merge(test_1, temp_8, on='indexing_surf_dist_bar', how='left').fillna(0) # dummy number for now\n",
    "test_1.rename(columns={'mean': 'bar_win_mean'}, inplace=True)\n",
    "\n",
    "# Groupby date & race, \n",
    "temp_8 = test_1.groupby(['indexing_date_race']).bar_win_mean.agg(['max'])\n",
    "\n",
    "# merge max back \n",
    "test_1 = pd.merge(test_1, temp_8, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'bar_win_max_race'}, inplace=True)\n",
    "\n",
    "# new column \n",
    "test_1 = test_1.assign(bar_win_race_f8 = \n",
    "               ((test_1['bar_win_mean'] - test_1['bar_win_max_race'] ) )) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# return df to original order:\n",
    "test_1 = test_1.sort_values(by=['indexing'], ascending =True)\n",
    "test_1 = test_1.reset_index()\n",
    "test_1 = test_1.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_1[['STORMY VIEW']].head()\n",
    "\n",
    "#df.loc[(df['horse_name'] == 'STORMY VIEW') ].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_1[['STORMY VIEW']].head()\n",
    "\n",
    "#test_1.loc[(test_1['date'] == '2019-07-07') & (test_1['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit; Rank & Wager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WAGER:\n",
    "# create a Python list of feature names\n",
    "X_trainfinal = train_1[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "y_trainfinal = train_1['lbw']\n",
    "\n",
    "\n",
    "X_testfinal = test_1[['feature_1', 'feature_1a', 'feature_1b', 'feature_1c', 'feature_1d', 'feature_1e',\n",
    "                   'feature_3', 'feature_3a', 'feature_3b', 'feature_3c', 'feature_3d', 'feature_3e',\n",
    "                   'jock_pct_race_f5', 'trainer_pct_race_f6', 'jock_trainer_win_pct_race_f7', 'bar_win_race_f8'\n",
    "                    ]]\n",
    "#y_testfinal = df_rc['lbw']\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit the model to the training data (learn the coefficients)\n",
    "linreg.fit(X_trainfinal, y_trainfinal)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_predfinal = linreg.predict(X_testfinal)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign y_pred_total back to lbw_pred in df:\n",
    "test_1 = test_1.assign(lbw_pred = y_predfinal)\n",
    "\n",
    "# Groupby date & race then (max_lbw) merge back to df for adj lbw_pred best back to 0:\n",
    "race_lbw_max = test_1.groupby(['indexing_date_race']).lbw_pred.agg(['max'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, race_lbw_max, on='indexing_date_race')\n",
    "test_1.rename(columns={'max': 'race_lbw_max'}, inplace=True)\n",
    "\n",
    "# return df to original order:\n",
    "test_1 = test_1.sort_values(by=['indexing'], ascending =True)\n",
    "test_1 = test_1.reset_index()\n",
    "test_1 = test_1.drop('index', axis=1)\n",
    "\n",
    "# new column in df 'race_lbw_pred' calc\n",
    "test_1 = test_1.assign(race_lbw_pred = ((test_1['lbw_pred'] - test_1['race_lbw_max'] ) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_1.tail(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign prob_pred from race_lbw_pred based on past data relationship to df\n",
    "test_1['prob_pred'] = [80 if x > -0.05 \n",
    "                   else 75 if x > -0.1\n",
    "                   else 70 if x > -0.15\n",
    "                   else 65 if x > -0.2\n",
    "                   else 60 if x > -0.25\n",
    "                   else 55 if x > -0.3\n",
    "                   else 50 if x > -0.55\n",
    "                   else 45 if x > -0.8 \n",
    "                   else 40 if x > -1.05\n",
    "                   else 35 if x > -1.3 \n",
    "                   else 30 if x > -1.8 \n",
    "                   else 25 if x > -2.3 \n",
    "                   else 20 if x > -2.85\n",
    "                   else 15 if x > -3.4\n",
    "                   else 10 if x > -4.75\n",
    "                   else  5 if x > -6.1\n",
    "                   else 1\n",
    "                   for x in test_1['race_lbw_pred']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby date & race then (race_prob_pred_sum) merge back to df for adj prob_pred to race_prob_pred:\n",
    "race_prob_pred_sum = test_1.groupby(['indexing_date_race']).prob_pred.agg(['sum'])\n",
    "\n",
    "# merge max back into df groupby indexing_date_race:\n",
    "test_1 = pd.merge(test_1, race_prob_pred_sum, on='indexing_date_race')\n",
    "test_1.rename(columns={'sum': 'race_prob_pred_sum'}, inplace=True)\n",
    "\n",
    "# new column in df 'race_prob_pred' calc\n",
    "test_1 = test_1.assign(race_prob_pred = ((test_1['prob_pred'] / test_1['race_prob_pred_sum'] ) * 100 )) \n",
    "\n",
    "# new column in df 'race_win_div_pred' calc\n",
    "test_1 = test_1.assign(race_win_div_pred = ((5 / ((test_1['race_prob_pred']) / 100)) )) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#test_1.loc[(test_1['date'] == '2019-07-07') & (test_1['race'] == 2)].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wagering strategy (filter for horses paying $21 or less, to avoid the longshot bias)\n",
    "df_3 = test_1[test_1.win_div_3 < 28]\n",
    "\n",
    "# save key columns:\n",
    "df_3 = df_3[['date', 'race', 'class', 'horse_name', 'lbw', 'race_lbw_pred','win_div_3', \n",
    "             'race_win_div_pred', 'indexing', 'total_count', 'win_count']]\n",
    "\n",
    "\n",
    "# add new column in df for times when 'win_div_3' exceeds (>) 'race_win_div_pred'   \n",
    "df_3 = df_3.assign(wager_pred = ((df_3['win_div_3'] - df_3['race_win_div_pred'] )  )) \n",
    "\n",
    "\n",
    "# narrow series for wagers with a positive sum ('wager_pred')\n",
    "df_3 = df_3[df_3.wager_pred > 0]\n",
    "\n",
    "\n",
    "# wager 5 on each\n",
    "df_3 = df_3.assign(wager = (-5)) \n",
    "\n",
    "\n",
    "df_3['return']=df_3[df_3['lbw']==0]['win_div_3']\n",
    "df_3['return'].fillna(0.5,inplace=True)  \n",
    "#df_3['return'].fillna(0,inplace=True) \n",
    "\n",
    "\n",
    "df_3['profit_loss'] = df_3['wager'] + df_3['return']  # assigned to a column\n",
    "\n",
    "\n",
    "df_3['accumulated_profit_loss'] = df_3['profit_loss'].cumsum()\n",
    "\n",
    "\n",
    "accumulated_profit_loss_1 = df_3[[\n",
    "    'date', 'race', 'horse_name', 'lbw', 'race_win_div_pred', 'win_div_3', 'wager', 'return', 'win_count']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>FOREVER WIN</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>HAPPY SAGA</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>12.0625</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>LETITGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>FULL LUCK</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>8.6875</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLD STAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6250</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>3</td>\n",
       "      <td>ANCIENT WARRIOR</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>10.1250</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>6</td>\n",
       "      <td>ATHLETICA</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>5.9375</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>7</td>\n",
       "      <td>HELIOSPHERE</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>7.9375</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>1</td>\n",
       "      <td>SUPER DENMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>2</td>\n",
       "      <td>BOY NEXT DOOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5625</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>4</td>\n",
       "      <td>SUCCESS COME TRUE</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>7.0625</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>6</td>\n",
       "      <td>PAPARAZZI</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>16.1875</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>9</td>\n",
       "      <td>CLASSIFIED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.1250</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race         horse_name  lbw  race_win_div_pred  win_div_3  wager  return  win_count\n",
       "16  2019-01-01     2        FOREVER WIN -8.3             7.2500         11     -5     0.5          0\n",
       "63  2019-01-01     6         HAPPY SAGA -7.4            12.0625         19     -5     0.5          0\n",
       "67  2019-01-01     7            LETITGO  0.0            13.0000         24     -5    24.0          1\n",
       "115 2019-01-06     1          FULL LUCK -4.1             8.6875         12     -5     0.5          0\n",
       "221 2019-01-11     2          GOLD STAR  0.0             9.6250         11     -5    11.0          1\n",
       "239 2019-01-11     3    ANCIENT WARRIOR -3.9            10.1250         23     -5     0.5          0\n",
       "273 2019-01-11     6          ATHLETICA -5.9             5.9375         17     -5     0.5          0\n",
       "282 2019-01-11     7        HELIOSPHERE -0.7             7.9375         10     -5     0.5          0\n",
       "308 2019-01-13     1       SUPER DENMAN  0.0            20.0000         24     -5    24.0          1\n",
       "320 2019-01-13     2      BOY NEXT DOOR  0.0             8.5625         20     -5    20.0          1\n",
       "343 2019-01-13     4  SUCCESS COME TRUE -1.5             7.0625         19     -5     0.5          0\n",
       "356 2019-01-13     6          PAPARAZZI -2.0            16.1875         18     -5     0.5          0\n",
       "391 2019-01-13     9         CLASSIFIED  0.0            12.1250         17     -5    17.0          1"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulated_profit_loss_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to append df2 at the end of df1 dataframe \n",
    "accumualted_profit_loss = accumulated_profit_loss_1.append(accumulated_profit_loss_2\n",
    "            ).append(accumulated_profit_loss_3).append(accumulated_profit_loss_4\n",
    "            ).append(accumulated_profit_loss_5).append(accumulated_profit_loss_6\n",
    "            ).append(accumulated_profit_loss_7).append(accumulated_profit_loss_8\n",
    "            ).append(accumulated_profit_loss_9).append(accumulated_profit_loss_10\n",
    "            ).append(accumulated_profit_loss_11).append(accumulated_profit_loss_12\n",
    "            ).append(accumulated_profit_loss_13)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumualted_profit_loss['profit_loss'] = accumualted_profit_loss['wager'\n",
    "                                    ] + accumualted_profit_loss['return']  # assigned to a new column\n",
    "\n",
    "accumualted_profit_loss['acc_profit_loss'] = accumualted_profit_loss['profit_loss'].cumsum()\n",
    "\n",
    "# add counter\n",
    "accumualted_profit_loss['total_wager_count'] = np.arange(len(accumualted_profit_loss)) \n",
    "\n",
    "accumualted_profit_loss['winning_wager_count'] = accumualted_profit_loss['win_count'].cumsum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>race</th>\n",
       "      <th>horse_name</th>\n",
       "      <th>lbw</th>\n",
       "      <th>race_win_div_pred</th>\n",
       "      <th>win_div_3</th>\n",
       "      <th>wager</th>\n",
       "      <th>return</th>\n",
       "      <th>win_count</th>\n",
       "      <th>profit_loss</th>\n",
       "      <th>acc_profit_loss</th>\n",
       "      <th>total_wager_count</th>\n",
       "      <th>winning_wager_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2</td>\n",
       "      <td>FOREVER WIN</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>6</td>\n",
       "      <td>HAPPY SAGA</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>12.062500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>7</td>\n",
       "      <td>LETITGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>FULL LUCK</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>8.687500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLD STAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.625000</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>3</td>\n",
       "      <td>ANCIENT WARRIOR</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>6</td>\n",
       "      <td>ATHLETICA</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>7</td>\n",
       "      <td>HELIOSPHERE</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>7.937500</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>1</td>\n",
       "      <td>SUPER DENMAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>2</td>\n",
       "      <td>BOY NEXT DOOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.562500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>4</td>\n",
       "      <td>SUCCESS COME TRUE</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>7.062500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>27.5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>6</td>\n",
       "      <td>PAPARAZZI</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>16.187500</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>9</td>\n",
       "      <td>CLASSIFIED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.125000</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>1</td>\n",
       "      <td>EVERYBODY HAPPY</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>10.687500</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>30.5</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>3</td>\n",
       "      <td>NO FUN NO GAIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.562500</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>42.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>4</td>\n",
       "      <td>SACRED DON</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.375000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>7</td>\n",
       "      <td>BE BEE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.687500</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>8</td>\n",
       "      <td>MACH</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>44.5</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>6</td>\n",
       "      <td>MAJESTIC EMPRESS</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-01-20</td>\n",
       "      <td>9</td>\n",
       "      <td>NIMBLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.437500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>4</td>\n",
       "      <td>ELENA OF AVALOR</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>19.142857</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>45.5</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>8</td>\n",
       "      <td>LUCKY HADA</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>22.666667</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>4</td>\n",
       "      <td>SALAMENCE</td>\n",
       "      <td>-8.7</td>\n",
       "      <td>17.187500</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>2</td>\n",
       "      <td>COLOUR PAINT</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>14.812500</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>4</td>\n",
       "      <td>SACRED CROIX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>6</td>\n",
       "      <td>EASTIGER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>8</td>\n",
       "      <td>IMPERIAL FALLS</td>\n",
       "      <td>-13.7</td>\n",
       "      <td>20.538462</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>53.5</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>2</td>\n",
       "      <td>JUPITER DRAGON</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>3</td>\n",
       "      <td>IRVING LIPSCHITZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>4</td>\n",
       "      <td>ACCUMULATION</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>11.187500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>60.5</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>6</td>\n",
       "      <td>QUARTER BACK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>77.5</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>6</td>\n",
       "      <td>EYE GUY</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>20.363636</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>7</td>\n",
       "      <td>BEBOP</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>68.5</td>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>8</td>\n",
       "      <td>MISTER YEOH</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>64.0</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>4</td>\n",
       "      <td>SACRED DON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.187500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>1</td>\n",
       "      <td>RUN THE DAY</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>2</td>\n",
       "      <td>TOOSBIES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>4</td>\n",
       "      <td>ELENA OF AVALOR</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>6</td>\n",
       "      <td>NADEEM SAPPHIRE</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>72.5</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>7</td>\n",
       "      <td>BE BEE</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>9.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>68.0</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>4</td>\n",
       "      <td>RUN THE DAY</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>40</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>GALVARINO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.687500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>41</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>SALVADOR</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>13.062500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>69.0</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>7</td>\n",
       "      <td>GLASGOW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.187500</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>3</td>\n",
       "      <td>NORTHERN SUN</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>86.5</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>6</td>\n",
       "      <td>KEEP WINNING</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.375000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>108.5</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>7</td>\n",
       "      <td>ELITE POWER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>118.5</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>7</td>\n",
       "      <td>MOKASTAR</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>114.0</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>8</td>\n",
       "      <td>IRVING LIPSCHITZ</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>8.312500</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>109.5</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>7</td>\n",
       "      <td>QUARTER BACK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.625000</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>121.5</td>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>2</td>\n",
       "      <td>VITTORIA PERFETTA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.687500</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>142.5</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>2</td>\n",
       "      <td>SUPER WIN</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>20.687500</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>138.0</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>6</td>\n",
       "      <td>CRACKING TOTTIE</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>133.5</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>7</td>\n",
       "      <td>MACH</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>129.0</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>8</td>\n",
       "      <td>DEBT COLLECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.812500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>3</td>\n",
       "      <td>FIRE AWAY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.625000</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>55</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-03-15</td>\n",
       "      <td>5</td>\n",
       "      <td>SUPER SIX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.687500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>INVINCIBLE MAN</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>21.625000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>164.5</td>\n",
       "      <td>57</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>3</td>\n",
       "      <td>GALVARINO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>7</td>\n",
       "      <td>-5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>166.5</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>8</td>\n",
       "      <td>BE BEE</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>10.312500</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>162.0</td>\n",
       "      <td>59</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2019-03-17</td>\n",
       "      <td>9</td>\n",
       "      <td>NIMBLE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2019-03-22</td>\n",
       "      <td>7</td>\n",
       "      <td>MOKASTAR</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>178.5</td>\n",
       "      <td>61</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>4</td>\n",
       "      <td>PAPERBACK TROOPER</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>16.687500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>174.0</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>8</td>\n",
       "      <td>SOUTHERN SPUR</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>169.5</td>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>1</td>\n",
       "      <td>TUN O'REILLY</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>13.625000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>165.0</td>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>2</td>\n",
       "      <td>YULONG EXPRESS</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>160.5</td>\n",
       "      <td>65</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>7</td>\n",
       "      <td>ARAMCO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>175.5</td>\n",
       "      <td>66</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>8</td>\n",
       "      <td>ELITE CONQUEST</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>171.0</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>10</td>\n",
       "      <td>IRONSIDE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.437500</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>68</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2019-04-12</td>\n",
       "      <td>4</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>10.937500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>187.5</td>\n",
       "      <td>69</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>1</td>\n",
       "      <td>OPTIMUM STAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.857143</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>204.5</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>2</td>\n",
       "      <td>YULONG EXPRESS</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>7.937500</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>200.0</td>\n",
       "      <td>71</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>4</td>\n",
       "      <td>COLOUR PAINT</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>195.5</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>5</td>\n",
       "      <td>OTTAWA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.312500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>211.5</td>\n",
       "      <td>73</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>7</td>\n",
       "      <td>MO ALMIGHTY</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>9</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>207.0</td>\n",
       "      <td>74</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2019-04-14</td>\n",
       "      <td>9</td>\n",
       "      <td>SILENT FORCE</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>202.5</td>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>2</td>\n",
       "      <td>STAGESHOW</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>198.0</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>3</td>\n",
       "      <td>YULONG FAST STEED</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>19.769231</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>193.5</td>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>3</td>\n",
       "      <td>FIRST CHOICE</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>16.062500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>189.0</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>5</td>\n",
       "      <td>RED DAWN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.625000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>79</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>6</td>\n",
       "      <td>ELITE POWER</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>20.937500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>204.5</td>\n",
       "      <td>80</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2019-04-19</td>\n",
       "      <td>8</td>\n",
       "      <td>BEBOP</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>200.0</td>\n",
       "      <td>81</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>2</td>\n",
       "      <td>LIM'S PASSION</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>13.125000</td>\n",
       "      <td>15</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>195.5</td>\n",
       "      <td>82</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>6</td>\n",
       "      <td>VENUS DE MILO</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>14.187500</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>191.0</td>\n",
       "      <td>83</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>8</td>\n",
       "      <td>NOWYOUSEE</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>16.875000</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>186.5</td>\n",
       "      <td>84</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2019-04-21</td>\n",
       "      <td>9</td>\n",
       "      <td>FULIFE KING</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>182.0</td>\n",
       "      <td>85</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>6</td>\n",
       "      <td>AUGUSTUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>7</td>\n",
       "      <td>GRATUS</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>12.937500</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>195.5</td>\n",
       "      <td>87</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>8</td>\n",
       "      <td>SACRED REBEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>209.5</td>\n",
       "      <td>88</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>9</td>\n",
       "      <td>BARTIMAEUS</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>205.0</td>\n",
       "      <td>89</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>2</td>\n",
       "      <td>LIM'S PASSION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>4</td>\n",
       "      <td>AABIR</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>213.5</td>\n",
       "      <td>91</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>5</td>\n",
       "      <td>SUPER SIX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>234.5</td>\n",
       "      <td>92</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>5</td>\n",
       "      <td>YULONG FAST STEED</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>230.0</td>\n",
       "      <td>93</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>2</td>\n",
       "      <td>JULIUS CAESAR</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>225.5</td>\n",
       "      <td>94</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>3</td>\n",
       "      <td>JUPITER DRAGON</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>11.812500</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>221.0</td>\n",
       "      <td>95</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>4</td>\n",
       "      <td>SIAM ROYAL ORCHID</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>10.125000</td>\n",
       "      <td>17</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>216.5</td>\n",
       "      <td>96</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>5</td>\n",
       "      <td>SUPER WIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.625000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>230.5</td>\n",
       "      <td>97</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-05-05</td>\n",
       "      <td>10</td>\n",
       "      <td>FAME STAR</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>15.812500</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>226.0</td>\n",
       "      <td>98</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>1</td>\n",
       "      <td>PAPERBACK TROOPER</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>9.875000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>221.5</td>\n",
       "      <td>99</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>4</td>\n",
       "      <td>PRIME TIME</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>217.0</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2019-05-10</td>\n",
       "      <td>5</td>\n",
       "      <td>WHITE TRUFFLE</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>7.062500</td>\n",
       "      <td>11</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>212.5</td>\n",
       "      <td>101</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>2</td>\n",
       "      <td>PAKATAN WARRIOR</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>7.375000</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>208.0</td>\n",
       "      <td>102</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>3</td>\n",
       "      <td>CIRCUIT MISSION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>103</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>6</td>\n",
       "      <td>NEO'S CLASSIC</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>11.625000</td>\n",
       "      <td>25</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>217.5</td>\n",
       "      <td>104</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2019-05-12</td>\n",
       "      <td>10</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>213.0</td>\n",
       "      <td>105</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>1</td>\n",
       "      <td>AABIR</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>208.5</td>\n",
       "      <td>106</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>3</td>\n",
       "      <td>WIND OF LIBERTY</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>17.687500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>204.0</td>\n",
       "      <td>107</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>4</td>\n",
       "      <td>CLARTON STAR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.437500</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>108</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>5</td>\n",
       "      <td>WELL DESERVED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>109</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>7</td>\n",
       "      <td>IMPLEMENT</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>234.5</td>\n",
       "      <td>110</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>3</td>\n",
       "      <td>BIG HEARTED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.687500</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>239.5</td>\n",
       "      <td>111</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2019-05-19</td>\n",
       "      <td>7</td>\n",
       "      <td>SUGARTIME JAZZ</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>16.562500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>235.0</td>\n",
       "      <td>112</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>5</td>\n",
       "      <td>BIRAZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.125000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>113</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>6</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>245.5</td>\n",
       "      <td>114</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2019-05-25</td>\n",
       "      <td>10</td>\n",
       "      <td>ELITE POWER</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.812500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>261.5</td>\n",
       "      <td>115</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>ONE WORLD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.562500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>268.5</td>\n",
       "      <td>116</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>4</td>\n",
       "      <td>RAPIDASH</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>264.0</td>\n",
       "      <td>117</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>6</td>\n",
       "      <td>VENUS DE MILO</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>259.5</td>\n",
       "      <td>118</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>SCORPIO</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>16.600000</td>\n",
       "      <td>26</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>255.0</td>\n",
       "      <td>119</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>5</td>\n",
       "      <td>WIJAYA</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>250.5</td>\n",
       "      <td>120</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>9</td>\n",
       "      <td>AUGUSTUS</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>12.562500</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>246.0</td>\n",
       "      <td>121</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>10</td>\n",
       "      <td>JULIUS CAESAR</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>241.5</td>\n",
       "      <td>122</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>4</td>\n",
       "      <td>GEB WARRIOR</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>15.875000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>237.0</td>\n",
       "      <td>123</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>4</td>\n",
       "      <td>WHITE TRUFFLE</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>19.538462</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>232.5</td>\n",
       "      <td>124</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>7</td>\n",
       "      <td>AUGUSTANO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.928571</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>254.5</td>\n",
       "      <td>125</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>8</td>\n",
       "      <td>LIM'S KNIGHT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.687500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>273.5</td>\n",
       "      <td>126</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>PEGASUS JUNIOR</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>269.0</td>\n",
       "      <td>127</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>2</td>\n",
       "      <td>VULCAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>128</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>3</td>\n",
       "      <td>ADMIRAL WINSTON</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>267.5</td>\n",
       "      <td>129</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>4</td>\n",
       "      <td>FEDERATION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.562500</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>275.5</td>\n",
       "      <td>130</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>5</td>\n",
       "      <td>IMPLEMENT</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>6.562500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>271.0</td>\n",
       "      <td>131</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2019-06-09</td>\n",
       "      <td>6</td>\n",
       "      <td>SPECIAL RAIN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.812500</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>132</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>2</td>\n",
       "      <td>FOREVER WIN</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>10.437500</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>284.5</td>\n",
       "      <td>133</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>3</td>\n",
       "      <td>SMILING PROUD</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>18.812500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>280.0</td>\n",
       "      <td>134</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>8</td>\n",
       "      <td>JULIUS CAESAR</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>275.5</td>\n",
       "      <td>135</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>2</td>\n",
       "      <td>ON LINE</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>6.687500</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>271.0</td>\n",
       "      <td>136</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>3</td>\n",
       "      <td>COUSTEAU</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>22.250000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>266.5</td>\n",
       "      <td>137</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>7</td>\n",
       "      <td>WIND TRAIL</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.562500</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>262.0</td>\n",
       "      <td>138</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2019-06-15</td>\n",
       "      <td>9</td>\n",
       "      <td>DRAGON DUKE</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>12.312500</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>257.5</td>\n",
       "      <td>139</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>2</td>\n",
       "      <td>CHARMING DIAMOND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.937500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>264.5</td>\n",
       "      <td>140</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2019-06-21</td>\n",
       "      <td>3</td>\n",
       "      <td>BOOM SHAKALAKA</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>13.562500</td>\n",
       "      <td>21</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>260.0</td>\n",
       "      <td>141</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>1</td>\n",
       "      <td>ONE WORLD</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>11.250000</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>255.5</td>\n",
       "      <td>142</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>2</td>\n",
       "      <td>AMAZING CHOICE</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>251.0</td>\n",
       "      <td>143</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>5</td>\n",
       "      <td>IMPLEMENT</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>12.937500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>246.5</td>\n",
       "      <td>144</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>7</td>\n",
       "      <td>THREEANDFOURPENCE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>23</td>\n",
       "      <td>-5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>264.5</td>\n",
       "      <td>145</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>GENTLEMEN AGREEMENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14</td>\n",
       "      <td>-5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>273.5</td>\n",
       "      <td>146</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>2</td>\n",
       "      <td>LIM'S TORPEDO</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>269.0</td>\n",
       "      <td>147</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>3</td>\n",
       "      <td>OTTAWA</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>16.375000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>264.5</td>\n",
       "      <td>148</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>4</td>\n",
       "      <td>ADIPSON</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>9.062500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>260.0</td>\n",
       "      <td>149</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2019-06-30</td>\n",
       "      <td>5</td>\n",
       "      <td>ATHLETICA</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>255.5</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>3</td>\n",
       "      <td>VULCAN</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>18</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>251.0</td>\n",
       "      <td>151</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4</td>\n",
       "      <td>PACIFIC MYSTICAL</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>7.375000</td>\n",
       "      <td>13</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>246.5</td>\n",
       "      <td>152</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>5</td>\n",
       "      <td>EASY DOES IT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.562500</td>\n",
       "      <td>22</td>\n",
       "      <td>-5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>263.5</td>\n",
       "      <td>153</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>7</td>\n",
       "      <td>REVOLUTION</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>18.187500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>259.0</td>\n",
       "      <td>154</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>8</td>\n",
       "      <td>SURPASS NATURAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>12</td>\n",
       "      <td>-5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>155</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>9</td>\n",
       "      <td>TURF PRINCESS</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>20.062500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>261.5</td>\n",
       "      <td>156</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>2</td>\n",
       "      <td>STORMY VIEW</td>\n",
       "      <td>-7.8</td>\n",
       "      <td>6.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>257.0</td>\n",
       "      <td>157</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>4</td>\n",
       "      <td>ROCKET STAR</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.312500</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>252.5</td>\n",
       "      <td>158</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>4</td>\n",
       "      <td>ADMIRAL WINSTON</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>13.545455</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>248.0</td>\n",
       "      <td>159</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>6</td>\n",
       "      <td>CHOCANTE</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>12.687500</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>243.5</td>\n",
       "      <td>160</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>9</td>\n",
       "      <td>LORD O'REILLY</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>27</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>239.0</td>\n",
       "      <td>161</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>2</td>\n",
       "      <td>AMAZING CHOICE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>10</td>\n",
       "      <td>-5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>162</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>3</td>\n",
       "      <td>MR BACHARACH</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>11.562500</td>\n",
       "      <td>20</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>239.5</td>\n",
       "      <td>163</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>4</td>\n",
       "      <td>RIVER RADIANCE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>7</td>\n",
       "      <td>-5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>241.5</td>\n",
       "      <td>164</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>5</td>\n",
       "      <td>BIG HEARTED</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>9.125000</td>\n",
       "      <td>16</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>237.0</td>\n",
       "      <td>165</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2019-07-21</td>\n",
       "      <td>10</td>\n",
       "      <td>IRVING LIPSCHITZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.812500</td>\n",
       "      <td>24</td>\n",
       "      <td>-5</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>166</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  race           horse_name   lbw  race_win_div_pred  win_div_3  wager  return  win_count  profit_loss  acc_profit_loss  total_wager_count  winning_wager_count\n",
       "0   2019-01-01     2          FOREVER WIN  -8.3           7.250000         11     -5     0.5          0         -4.5             -4.5                  0                    0\n",
       "1   2019-01-01     6           HAPPY SAGA  -7.4          12.062500         19     -5     0.5          0         -4.5             -9.0                  1                    0\n",
       "2   2019-01-01     7              LETITGO   0.0          13.000000         24     -5    24.0          1         19.0             10.0                  2                    1\n",
       "3   2019-01-06     1            FULL LUCK  -4.1           8.687500         12     -5     0.5          0         -4.5              5.5                  3                    1\n",
       "4   2019-01-11     2            GOLD STAR   0.0           9.625000         11     -5    11.0          1          6.0             11.5                  4                    2\n",
       "5   2019-01-11     3      ANCIENT WARRIOR  -3.9          10.125000         23     -5     0.5          0         -4.5              7.0                  5                    2\n",
       "6   2019-01-11     6            ATHLETICA  -5.9           5.937500         17     -5     0.5          0         -4.5              2.5                  6                    2\n",
       "7   2019-01-11     7          HELIOSPHERE  -0.7           7.937500         10     -5     0.5          0         -4.5             -2.0                  7                    2\n",
       "8   2019-01-13     1         SUPER DENMAN   0.0          20.000000         24     -5    24.0          1         19.0             17.0                  8                    3\n",
       "9   2019-01-13     2        BOY NEXT DOOR   0.0           8.562500         20     -5    20.0          1         15.0             32.0                  9                    4\n",
       "10  2019-01-13     4    SUCCESS COME TRUE  -1.5           7.062500         19     -5     0.5          0         -4.5             27.5                 10                    4\n",
       "11  2019-01-13     6            PAPARAZZI  -2.0          16.187500         18     -5     0.5          0         -4.5             23.0                 11                    4\n",
       "12  2019-01-13     9           CLASSIFIED   0.0          12.125000         17     -5    17.0          1         12.0             35.0                 12                    5\n",
       "13  2019-01-18     1      EVERYBODY HAPPY  -2.3          10.687500         13     -5     0.5          0         -4.5             30.5                 13                    5\n",
       "14  2019-01-18     3       NO FUN NO GAIN   0.0          14.562500         17     -5    17.0          1         12.0             42.5                 14                    6\n",
       "15  2019-01-18     4           SACRED DON  -1.0          13.375000         16     -5     0.5          0         -4.5             38.0                 15                    6\n",
       "16  2019-01-18     7               BE BEE   0.0           9.687500         16     -5    16.0          1         11.0             49.0                 16                    7\n",
       "17  2019-01-18     8                 MACH  -4.0          14.250000         25     -5     0.5          0         -4.5             44.5                 17                    7\n",
       "18  2019-01-20     6     MAJESTIC EMPRESS  -1.0          19.750000         27     -5     0.5          0         -4.5             40.0                 18                    7\n",
       "19  2019-01-20     9               NIMBLE   0.0          13.437500         15     -5    15.0          1         10.0             50.0                 19                    8\n",
       "20  2019-01-25     4      ELENA OF AVALOR  -2.3          19.142857         26     -5     0.5          0         -4.5             45.5                 20                    8\n",
       "21  2019-01-25     8           LUCKY HADA  -1.5          22.666667         25     -5     0.5          0         -4.5             41.0                 21                    8\n",
       "22  2019-02-01     4            SALAMENCE  -8.7          17.187500         25     -5     0.5          0         -4.5             36.5                 22                    8\n",
       "23  2019-02-03     2         COLOUR PAINT  -5.2          14.812500         25     -5     0.5          0         -4.5             32.0                 23                    8\n",
       "24  2019-02-03     4         SACRED CROIX   0.0           6.625000         19     -5    19.0          1         14.0             46.0                 24                    9\n",
       "25  2019-02-03     6             EASTIGER   0.0           8.312500         17     -5    17.0          1         12.0             58.0                 25                   10\n",
       "26  2019-02-03     8       IMPERIAL FALLS -13.7          20.538462         22     -5     0.5          0         -4.5             53.5                 26                   10\n",
       "27  2019-02-06     2       JUPITER DRAGON  -2.7          16.062500         19     -5     0.5          0         -4.5             49.0                 27                   10\n",
       "28  2019-02-06     3     IRVING LIPSCHITZ   0.0           7.125000         21     -5    21.0          1         16.0             65.0                 28                   11\n",
       "29  2019-02-06     4         ACCUMULATION  -6.5          11.187500         19     -5     0.5          0         -4.5             60.5                 29                   11\n",
       "30  2019-02-06     6         QUARTER BACK   0.0          14.000000         22     -5    22.0          1         17.0             77.5                 30                   12\n",
       "31  2019-02-06     6              EYE GUY  -5.1          20.363636         21     -5     0.5          0         -4.5             73.0                 31                   12\n",
       "32  2019-02-06     7                BEBOP  -0.5          16.062500         21     -5     0.5          0         -4.5             68.5                 32                   12\n",
       "33  2019-02-06     8          MISTER YEOH  -1.7          17.687500         21     -5     0.5          0         -4.5             64.0                 33                   12\n",
       "34  2019-02-08     4           SACRED DON   0.0          14.187500         15     -5    15.0          1         10.0             74.0                 34                   13\n",
       "35  2019-02-15     1          RUN THE DAY  -1.6           7.562500         20     -5     0.5          0         -4.5             69.5                 35                   13\n",
       "36  2019-02-17     2             TOOSBIES   0.0          13.875000         17     -5    17.0          1         12.0             81.5                 36                   14\n",
       "37  2019-02-17     4      ELENA OF AVALOR  -0.5          11.000000         15     -5     0.5          0         -4.5             77.0                 37                   14\n",
       "38  2019-02-17     6      NADEEM SAPPHIRE  -2.1          18.250000         25     -5     0.5          0         -4.5             72.5                 38                   14\n",
       "39  2019-02-17     7               BE BEE  -0.5           9.375000         18     -5     0.5          0         -4.5             68.0                 39                   14\n",
       "40  2019-02-22     4          RUN THE DAY  -9.5           7.562500         20     -5     0.5          0         -4.5             63.5                 40                   14\n",
       "41  2019-03-01     2            GALVARINO   0.0           5.687500         15     -5    15.0          1         10.0             73.5                 41                   15\n",
       "42  2019-03-01     3             SALVADOR  -0.8          13.062500         15     -5     0.5          0         -4.5             69.0                 42                   15\n",
       "43  2019-03-01     7              GLASGOW   0.0          20.187500         27     -5    27.0          1         22.0             91.0                 43                   16\n",
       "44  2019-03-03     3         NORTHERN SUN -14.0          14.500000         25     -5     0.5          0         -4.5             86.5                 44                   16\n",
       "45  2019-03-03     6         KEEP WINNING   0.0          24.375000         27     -5    27.0          1         22.0            108.5                 45                   17\n",
       "46  2019-03-03     7          ELITE POWER   0.0          14.500000         15     -5    15.0          1         10.0            118.5                 46                   18\n",
       "47  2019-03-03     7             MOKASTAR  -1.0          23.200000         24     -5     0.5          0         -4.5            114.0                 47                   18\n",
       "48  2019-03-03     8     IRVING LIPSCHITZ  -3.9           8.312500         17     -5     0.5          0         -4.5            109.5                 48                   18\n",
       "49  2019-03-08     7         QUARTER BACK   0.0           9.625000         17     -5    17.0          1         12.0            121.5                 49                   19\n",
       "50  2019-03-10     2    VITTORIA PERFETTA   0.0          20.687500         26     -5    26.0          1         21.0            142.5                 50                   20\n",
       "51  2019-03-10     2            SUPER WIN  -3.7          20.687500         26     -5     0.5          0         -4.5            138.0                 51                   20\n",
       "52  2019-03-10     6      CRACKING TOTTIE  -3.2          18.250000         25     -5     0.5          0         -4.5            133.5                 52                   20\n",
       "53  2019-03-10     7                 MACH  -6.4          14.250000         20     -5     0.5          0         -4.5            129.0                 53                   20\n",
       "54  2019-03-10     8       DEBT COLLECTOR   0.0          10.812500         22     -5    22.0          1         17.0            146.0                 54                   21\n",
       "55  2019-03-15     3            FIRE AWAY   0.0           6.625000         12     -5    12.0          1          7.0            153.0                 55                   22\n",
       "56  2019-03-15     5            SUPER SIX   0.0          20.687500         21     -5    21.0          1         16.0            169.0                 56                   23\n",
       "57  2019-03-17     1       INVINCIBLE MAN  -4.5          21.625000         22     -5     0.5          0         -4.5            164.5                 57                   23\n",
       "58  2019-03-17     3            GALVARINO   0.0           6.125000          7     -5     7.0          1          2.0            166.5                 58                   24\n",
       "59  2019-03-17     8               BE BEE  -3.8          10.312500         16     -5     0.5          0         -4.5            162.0                 59                   24\n",
       "60  2019-03-17     9               NIMBLE   0.0          16.750000         26     -5    26.0          1         21.0            183.0                 60                   25\n",
       "61  2019-03-22     7             MOKASTAR  -2.3          22.333333         24     -5     0.5          0         -4.5            178.5                 61                   25\n",
       "62  2019-04-05     4    PAPERBACK TROOPER  -0.8          16.687500         23     -5     0.5          0         -4.5            174.0                 62                   25\n",
       "63  2019-04-05     8        SOUTHERN SPUR  -4.5          13.750000         18     -5     0.5          0         -4.5            169.5                 63                   25\n",
       "64  2019-04-07     1         TUN O'REILLY  -6.4          13.625000         25     -5     0.5          0         -4.5            165.0                 64                   25\n",
       "65  2019-04-07     2       YULONG EXPRESS  -2.1          21.000000         27     -5     0.5          0         -4.5            160.5                 65                   25\n",
       "66  2019-04-07     7               ARAMCO   0.0          12.500000         20     -5    20.0          1         15.0            175.5                 66                   26\n",
       "67  2019-04-07     8       ELITE CONQUEST  -2.5          12.500000         26     -5     0.5          0         -4.5            171.0                 67                   26\n",
       "68  2019-04-07    10             IRONSIDE   0.0          24.437500         26     -5    26.0          1         21.0            192.0                 68                   27\n",
       "69  2019-04-12     4         LIM'S KNIGHT  -0.5          10.937500         15     -5     0.5          0         -4.5            187.5                 69                   27\n",
       "70  2019-04-14     1         OPTIMUM STAR   0.0          21.857143         22     -5    22.0          1         17.0            204.5                 70                   28\n",
       "71  2019-04-14     2       YULONG EXPRESS  -1.5           7.937500         15     -5     0.5          0         -4.5            200.0                 71                   28\n",
       "72  2019-04-14     4         COLOUR PAINT  -5.0          11.375000         16     -5     0.5          0         -4.5            195.5                 72                   28\n",
       "73  2019-04-14     5               OTTAWA   0.0          17.312500         21     -5    21.0          1         16.0            211.5                 73                   29\n",
       "74  2019-04-14     7          MO ALMIGHTY  -3.0           7.750000          9     -5     0.5          0         -4.5            207.0                 74                   29\n",
       "75  2019-04-14     9         SILENT FORCE  -5.7          10.437500         22     -5     0.5          0         -4.5            202.5                 75                   29\n",
       "76  2019-04-19     2            STAGESHOW  -8.6          13.000000         27     -5     0.5          0         -4.5            198.0                 76                   29\n",
       "77  2019-04-19     3    YULONG FAST STEED  -1.3          19.769231         24     -5     0.5          0         -4.5            193.5                 77                   29\n",
       "78  2019-04-19     3         FIRST CHOICE  -5.3          16.062500         21     -5     0.5          0         -4.5            189.0                 78                   29\n",
       "79  2019-04-19     5             RED DAWN   0.0          10.625000         25     -5    25.0          1         20.0            209.0                 79                   30\n",
       "80  2019-04-19     6          ELITE POWER  -1.4          20.937500         23     -5     0.5          0         -4.5            204.5                 80                   30\n",
       "81  2019-04-19     8                BEBOP  -5.9          15.750000         23     -5     0.5          0         -4.5            200.0                 81                   30\n",
       "82  2019-04-21     2        LIM'S PASSION  -2.6          13.125000         15     -5     0.5          0         -4.5            195.5                 82                   30\n",
       "83  2019-04-21     6        VENUS DE MILO -10.7          14.187500         26     -5     0.5          0         -4.5            191.0                 83                   30\n",
       "84  2019-04-21     8            NOWYOUSEE  -3.0          16.875000         17     -5     0.5          0         -4.5            186.5                 84                   30\n",
       "85  2019-04-21     9          FULIFE KING  -1.1          15.125000         21     -5     0.5          0         -4.5            182.0                 85                   30\n",
       "86  2019-04-26     6             AUGUSTUS   0.0          17.000000         23     -5    23.0          1         18.0            200.0                 86                   31\n",
       "87  2019-04-26     7               GRATUS  -4.5          12.937500         18     -5     0.5          0         -4.5            195.5                 87                   31\n",
       "88  2019-04-26     8         SACRED REBEL   0.0           9.562500         19     -5    19.0          1         14.0            209.5                 88                   32\n",
       "89  2019-04-26     9           BARTIMAEUS  -2.3          17.250000         25     -5     0.5          0         -4.5            205.0                 89                   32\n",
       "90  2019-05-03     2        LIM'S PASSION   0.0          11.375000         18     -5    18.0          1         13.0            218.0                 90                   33\n",
       "91  2019-05-03     4                AABIR  -3.1           7.500000         20     -5     0.5          0         -4.5            213.5                 91                   33\n",
       "92  2019-05-03     5            SUPER SIX   0.0          18.400000         26     -5    26.0          1         21.0            234.5                 92                   34\n",
       "93  2019-05-03     5    YULONG FAST STEED  -3.8          11.500000         20     -5     0.5          0         -4.5            230.0                 93                   34\n",
       "94  2019-05-05     2        JULIUS CAESAR  -1.4          15.125000         22     -5     0.5          0         -4.5            225.5                 94                   34\n",
       "95  2019-05-05     3       JUPITER DRAGON  -7.8          11.812500         18     -5     0.5          0         -4.5            221.0                 95                   34\n",
       "96  2019-05-05     4    SIAM ROYAL ORCHID  -0.6          10.125000         17     -5     0.5          0         -4.5            216.5                 96                   34\n",
       "97  2019-05-05     5            SUPER WIN   0.0          13.625000         19     -5    19.0          1         14.0            230.5                 97                   35\n",
       "98  2019-05-05    10            FAME STAR  -2.8          15.812500         16     -5     0.5          0         -4.5            226.0                 98                   35\n",
       "99  2019-05-10     1    PAPERBACK TROOPER  -1.5           9.875000         22     -5     0.5          0         -4.5            221.5                 99                   35\n",
       "100 2019-05-10     4           PRIME TIME  -4.9           9.562500         11     -5     0.5          0         -4.5            217.0                100                   35\n",
       "101 2019-05-10     5        WHITE TRUFFLE  -0.6           7.062500         11     -5     0.5          0         -4.5            212.5                101                   35\n",
       "102 2019-05-12     2      PAKATAN WARRIOR  -6.3           7.375000         24     -5     0.5          0         -4.5            208.0                102                   35\n",
       "103 2019-05-12     3      CIRCUIT MISSION   0.0          13.875000         19     -5    19.0          1         14.0            222.0                103                   36\n",
       "104 2019-05-12     6        NEO'S CLASSIC  -4.7          11.625000         25     -5     0.5          0         -4.5            217.5                104                   36\n",
       "105 2019-05-12    10         LIM'S KNIGHT  -4.8          17.687500         23     -5     0.5          0         -4.5            213.0                105                   36\n",
       "106 2019-05-17     1                AABIR  -0.8          25.300000         27     -5     0.5          0         -4.5            208.5                106                   36\n",
       "107 2019-05-17     3      WIND OF LIBERTY  -3.6          17.687500         22     -5     0.5          0         -4.5            204.0                107                   36\n",
       "108 2019-05-17     4         CLARTON STAR   0.0          16.437500         19     -5    19.0          1         14.0            218.0                108                   37\n",
       "109 2019-05-17     5        WELL DESERVED   0.0          14.500000         26     -5    26.0          1         21.0            239.0                109                   38\n",
       "110 2019-05-17     7            IMPLEMENT  -0.5           8.500000         27     -5     0.5          0         -4.5            234.5                110                   38\n",
       "111 2019-05-19     3          BIG HEARTED   0.0           5.687500         10     -5    10.0          1          5.0            239.5                111                   39\n",
       "112 2019-05-19     7       SUGARTIME JAZZ  -0.5          16.562500         24     -5     0.5          0         -4.5            235.0                112                   39\n",
       "113 2019-05-25     5                BIRAZ   0.0          16.125000         20     -5    20.0          1         15.0            250.0                113                   40\n",
       "114 2019-05-25     6         LIM'S KNIGHT  -2.7          14.000000         19     -5     0.5          0         -4.5            245.5                114                   40\n",
       "115 2019-05-25    10          ELITE POWER   0.0          13.812500         21     -5    21.0          1         16.0            261.5                115                   41\n",
       "116 2019-05-31     1            ONE WORLD   0.0           7.562500         12     -5    12.0          1          7.0            268.5                116                   42\n",
       "117 2019-05-31     4             RAPIDASH  -2.5           5.750000         20     -5     0.5          0         -4.5            264.0                117                   42\n",
       "118 2019-05-31     6        VENUS DE MILO  -6.7          14.250000         19     -5     0.5          0         -4.5            259.5                118                   42\n",
       "119 2019-06-01     1              SCORPIO  -4.4          16.600000         26     -5     0.5          0         -4.5            255.0                119                   42\n",
       "120 2019-06-01     5               WIJAYA  -1.5          11.500000         16     -5     0.5          0         -4.5            250.5                120                   42\n",
       "121 2019-06-01     9             AUGUSTUS  -0.5          12.562500         18     -5     0.5          0         -4.5            246.0                121                   42\n",
       "122 2019-06-01    10        JULIUS CAESAR  -7.6          15.125000         22     -5     0.5          0         -4.5            241.5                122                   42\n",
       "123 2019-06-07     4          GEB WARRIOR  -0.3          15.875000         22     -5     0.5          0         -4.5            237.0                123                   42\n",
       "124 2019-06-07     4        WHITE TRUFFLE  -2.1          19.538462         22     -5     0.5          0         -4.5            232.5                124                   42\n",
       "125 2019-06-07     7            AUGUSTANO   0.0          21.928571         27     -5    27.0          1         22.0            254.5                125                   43\n",
       "126 2019-06-07     8         LIM'S KNIGHT   0.0          16.687500         24     -5    24.0          1         19.0            273.5                126                   44\n",
       "127 2019-06-09     1       PEGASUS JUNIOR  -3.6          20.312500         27     -5     0.5          0         -4.5            269.0                127                   44\n",
       "128 2019-06-09     2               VULCAN   0.0           5.750000          8     -5     8.0          1          3.0            272.0                128                   45\n",
       "129 2019-06-09     3      ADMIRAL WINSTON  -2.8           6.187500         18     -5     0.5          0         -4.5            267.5                129                   45\n",
       "130 2019-06-09     4           FEDERATION   0.0           9.562500         13     -5    13.0          1          8.0            275.5                130                   46\n",
       "131 2019-06-09     5            IMPLEMENT  -1.8           6.562500         23     -5     0.5          0         -4.5            271.0                131                   46\n",
       "132 2019-06-09     6         SPECIAL RAIN   0.0          17.812500         23     -5    23.0          1         18.0            289.0                132                   47\n",
       "133 2019-06-14     2          FOREVER WIN  -2.3          10.437500         13     -5     0.5          0         -4.5            284.5                133                   47\n",
       "134 2019-06-14     3        SMILING PROUD  -7.4          18.812500         22     -5     0.5          0         -4.5            280.0                134                   47\n",
       "135 2019-06-14     8        JULIUS CAESAR  -6.9          22.250000         23     -5     0.5          0         -4.5            275.5                135                   47\n",
       "136 2019-06-15     2              ON LINE  -1.1           6.687500         10     -5     0.5          0         -4.5            271.0                136                   47\n",
       "137 2019-06-15     3             COUSTEAU  -2.6          22.250000         23     -5     0.5          0         -4.5            266.5                137                   47\n",
       "138 2019-06-15     7           WIND TRAIL  -1.0          13.562500         27     -5     0.5          0         -4.5            262.0                138                   47\n",
       "139 2019-06-15     9          DRAGON DUKE  -1.6          12.312500         27     -5     0.5          0         -4.5            257.5                139                   47\n",
       "140 2019-06-21     2     CHARMING DIAMOND   0.0           5.937500         12     -5    12.0          1          7.0            264.5                140                   48\n",
       "141 2019-06-21     3       BOOM SHAKALAKA  -0.3          13.562500         21     -5     0.5          0         -4.5            260.0                141                   48\n",
       "142 2019-06-28     1            ONE WORLD  -4.1          11.250000         22     -5     0.5          0         -4.5            255.5                142                   48\n",
       "143 2019-06-28     2       AMAZING CHOICE  -1.5          16.666667         19     -5     0.5          0         -4.5            251.0                143                   48\n",
       "144 2019-06-28     5            IMPLEMENT  -1.1          12.937500         20     -5     0.5          0         -4.5            246.5                144                   48\n",
       "145 2019-06-28     7    THREEANDFOURPENCE   0.0          18.000000         23     -5    23.0          1         18.0            264.5                145                   49\n",
       "146 2019-06-30     1  GENTLEMEN AGREEMENT   0.0          13.000000         14     -5    14.0          1          9.0            273.5                146                   50\n",
       "147 2019-06-30     2        LIM'S TORPEDO  -1.2           5.812500         24     -5     0.5          0         -4.5            269.0                147                   50\n",
       "148 2019-06-30     3               OTTAWA  -5.9          16.375000         18     -5     0.5          0         -4.5            264.5                148                   50\n",
       "149 2019-06-30     4              ADIPSON  -0.8           9.062500         12     -5     0.5          0         -4.5            260.0                149                   50\n",
       "150 2019-06-30     5            ATHLETICA  -0.4          17.000000         19     -5     0.5          0         -4.5            255.5                150                   50\n",
       "151 2019-07-05     3               VULCAN  -5.5          13.500000         18     -5     0.5          0         -4.5            251.0                151                   50\n",
       "152 2019-07-05     4     PACIFIC MYSTICAL  -5.6           7.375000         13     -5     0.5          0         -4.5            246.5                152                   50\n",
       "153 2019-07-05     5         EASY DOES IT   0.0          13.562500         22     -5    22.0          1         17.0            263.5                153                   51\n",
       "154 2019-07-05     7           REVOLUTION  -0.7          18.187500         20     -5     0.5          0         -4.5            259.0                154                   51\n",
       "155 2019-07-05     8      SURPASS NATURAL   0.0           5.812500         12     -5    12.0          1          7.0            266.0                155                   52\n",
       "156 2019-07-05     9        TURF PRINCESS  -0.5          20.062500         24     -5     0.5          0         -4.5            261.5                156                   52\n",
       "157 2019-07-07     2          STORMY VIEW  -7.8           6.125000          8     -5     0.5          0         -4.5            257.0                157                   52\n",
       "158 2019-07-07     4          ROCKET STAR  -2.0           9.312500         10     -5     0.5          0         -4.5            252.5                158                   52\n",
       "159 2019-07-07     4      ADMIRAL WINSTON  -5.2          13.545455         20     -5     0.5          0         -4.5            248.0                159                   52\n",
       "160 2019-07-07     6             CHOCANTE  -2.3          12.687500         16     -5     0.5          0         -4.5            243.5                160                   52\n",
       "161 2019-07-07     9        LORD O'REILLY -10.9          13.500000         27     -5     0.5          0         -4.5            239.0                161                   52\n",
       "162 2019-07-12     2       AMAZING CHOICE   0.0           8.250000         10     -5    10.0          1          5.0            244.0                162                   53\n",
       "163 2019-07-19     3         MR BACHARACH  -3.6          11.562500         20     -5     0.5          0         -4.5            239.5                163                   53\n",
       "164 2019-07-19     4       RIVER RADIANCE   0.0           5.625000          7     -5     7.0          1          2.0            241.5                164                   54\n",
       "165 2019-07-19     5          BIG HEARTED  -2.6           9.125000         16     -5     0.5          0         -4.5            237.0                165                   54\n",
       "166 2019-07-21    10     IRVING LIPSCHITZ   0.0          15.812500         24     -5    24.0          1         19.0            256.0                166                   55"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "accumualted_profit_loss.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 431,
       "width": 648
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Screen wagering on favorites which pay more than our fair odds (win_div_pred) results in these bets \n",
    "# of which nearly nearly 40% are winnners  \n",
    "\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "x = 'date'\n",
    "y = (['total_wager_count', 'winning_wager_count'])\n",
    "accumualted_profit_loss.plot.line(x, y)\n",
    "plt.title('Total Number of Wagers & Number of Winners YTD-2019')\n",
    "plt.ylabel('Profit/Loss')\n",
    "plt.gcf().set_size_inches(9, 6)\n",
    "plt.grid(True)\n",
    "plt.figtext(0.995, 0.01, u'\\u00a9 Charles Spencer 2019', ha='right', va='bottom')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 431,
       "width": 648
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('dark_background')\n",
    "\n",
    "accumualted_profit_loss.plot.line(x='date', y='acc_profit_loss')\n",
    "plt.title('Accumulated Profit/Loss on $5 Win Bets YTD-2019')\n",
    "plt.ylabel('Profit/Loss')\n",
    "plt.gcf().set_size_inches(9, 6)\n",
    "plt.grid(True)\n",
    "plt.figtext(0.995, 0.01, u'\\u00a9 Charles Spencer 2019', ha='right', va='bottom')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned dataset back to folder\n",
    "accumualted_profit_loss.to_csv('./datasets/accumualted_profit_loss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betting level:\n",
    "# <21 $60\n",
    "# <25 $161\n",
    "# <27 $218     151; 101; 50\n",
    "# <28 $244<<<< 163; 110; 53\n",
    "# <29 $176     178; 125; 53\n",
    "# <30 $182      182; 129; 54\n",
    "# <35 $ 81 . . .  225; 169; 59\n",
    "# <40 $ 7       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
